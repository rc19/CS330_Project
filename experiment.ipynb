{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Utility functions. \"\"\"\n",
    "import pdb\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "## Loss utilities\n",
    "def cross_entropy_loss(pred, label, k_shot):\n",
    "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=tf.stop_gradient(label)) / k_shot)\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(labels, predictions), dtype=tf.float32))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Data loading scripts\"\"\"\n",
    "from scipy import misc\n",
    "import imageio\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "from PIL import Image\n",
    "\n",
    "def get_images(paths, labels, n_samples=None, shuffle=True):\n",
    "    \"\"\"\n",
    "    Takes a set of character folders and labels and returns paths to image files\n",
    "    paired with labels.\n",
    "    Args:\n",
    "    paths: A list of character folders\n",
    "    labels: List or numpy array of same length as paths\n",
    "    n_samples: Number of images to retrieve per character\n",
    "    Returns:\n",
    "    List of (label, image_path) tuples\n",
    "    \"\"\"\n",
    "    if n_samples is not None:\n",
    "        sampler = lambda x: random.sample(x, n_samples)\n",
    "    else:\n",
    "        sampler = lambda x: x\n",
    "    images_labels = [(i, os.path.join(path, image))\n",
    "           for i, path in zip(labels, paths)\n",
    "           for image in sampler(os.listdir(path))]\n",
    "    if shuffle:\n",
    "        random.shuffle(images_labels)\n",
    "    return images_labels\n",
    "\n",
    "\n",
    "def image_file_to_array(filename, dim_input, shear=None, scale=None):\n",
    "    \"\"\"\n",
    "    Takes an image path and returns numpy array\n",
    "    Args:\n",
    "    filename: Image filename\n",
    "    dim_input: Flattened shape of image\n",
    "    Returns:\n",
    "    1 channel image\n",
    "    \"\"\"\n",
    "    im = Image.open(filename)\n",
    "    im = im.resize((28,28), resample=Image.LANCZOS)\n",
    "    im.save('tmpfile.png')\n",
    "    image = imageio.imread('tmpfile.png')\n",
    "#     image = imageio.imread(filename)\n",
    "    # pdb.set_trace()\n",
    "    if shear is not None:\n",
    "        afine_tf = transform.AffineTransform(shear=shear)\n",
    "        image = transform.warp(image, inverse_map=afine_tf)*255.0\n",
    "\n",
    "    elif scale is not None:\n",
    "        afine_tf = transform.AffineTransform(scale=scale)*255.0\n",
    "        image = transform.warp(image, inverse_map=afine_tf)\n",
    "    # pdb.set_trace()\n",
    "    image = image.reshape([dim_input])\n",
    "    image = image.astype(np.float32) / 255\n",
    "    image = 1.0 - image\n",
    "    return image\n",
    "\n",
    "\n",
    "class DataGenerator(object):\n",
    "    \"\"\"\n",
    "    Data Generator capable of generating batches of Omniglot data.\n",
    "    A \"class\" is considered a class of omniglot digits.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, num_samples_per_class, num_meta_test_classes, num_meta_test_samples_per_class, config={}):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          num_classes: Number of classes for classification (K-way)\n",
    "          num_samples_per_class: num samples to generate per class in one batch\n",
    "          num_meta_test_classes: Number of classes for classification (K-way) at meta-test time\n",
    "          num_meta_test_samples_per_class: num samples to generate per class in one batch at meta-test time\n",
    "          batch_size: size of meta batch size (e.g. number of functions)\n",
    "        \"\"\"\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.num_classes = num_classes\n",
    "        self.num_meta_test_samples_per_class = num_meta_test_samples_per_class\n",
    "        self.num_meta_test_classes = num_meta_test_classes\n",
    "\n",
    "        data_folder = config.get('data_folder', './omniglot_resized')\n",
    "        self.img_size = config.get('img_size', (28, 28))\n",
    "\n",
    "        self.dim_input = np.prod(self.img_size)\n",
    "        self.dim_output = self.num_classes\n",
    "\n",
    "        character_folders = [os.path.join(data_folder, family, character)\n",
    "                   for family in os.listdir(data_folder)\n",
    "                   if os.path.isdir(os.path.join(data_folder, family))\n",
    "                   for character in os.listdir(os.path.join(data_folder, family))\n",
    "                   if os.path.isdir(os.path.join(data_folder, family, character))]\n",
    "\n",
    "        random.seed(123)\n",
    "        random.shuffle(character_folders)\n",
    "        num_val = 100\n",
    "        num_train = 1100\n",
    "        self.metatrain_character_folders = character_folders[: num_train]\n",
    "        self.metaval_character_folders = character_folders[\n",
    "          num_train:num_train + num_val]\n",
    "        self.metatest_character_folders = character_folders[\n",
    "          num_train + num_val:]\n",
    "\n",
    "    def sample_batch(self, batch_type, batch_size, shuffle=True, swap=False, shear=None, scale=None):\n",
    "        \"\"\"\n",
    "        Samples a batch for training, validation, or testing\n",
    "        Args:\n",
    "          batch_type: meta_train/meta_val/meta_test\n",
    "          shuffle: randomly shuffle classes or not\n",
    "          swap: swap number of classes (N) and number of samples per class (K) or not\n",
    "        Returns:\n",
    "          A a tuple of (1) Image batch and (2) Label batch where\n",
    "          image batch has shape [B, N, K, 784] and label batch has shape [B, N, K, N] if swap is False\n",
    "          where B is batch size, K is number of samples per class, N is number of classes\n",
    "        \"\"\"\n",
    "        if batch_type == \"meta_train\":\n",
    "            folders = self.metatrain_character_folders\n",
    "            num_classes = self.num_classes\n",
    "            num_samples_per_class = self.num_samples_per_class\n",
    "        elif batch_type == \"meta_val\":\n",
    "            folders = self.metaval_character_folders\n",
    "            num_classes = self.num_classes\n",
    "            num_samples_per_class = self.num_samples_per_class\n",
    "        else:\n",
    "            folders = self.metatest_character_folders\n",
    "            num_classes = self.num_meta_test_classes\n",
    "            num_samples_per_class = self.num_meta_test_samples_per_class\n",
    "\n",
    "        all_image_batches, all_label_batches = [], []\n",
    "        for i in range(batch_size):\n",
    "            sampled_character_folders = random.sample(\n",
    "            folders, num_classes)\n",
    "            labels_and_images = get_images(sampled_character_folders, range(\n",
    "            num_classes), n_samples=num_samples_per_class, shuffle=False)\n",
    "            labels = [li[0] for li in labels_and_images]\n",
    "            images = [image_file_to_array(\n",
    "            li[1], self.dim_input,shear,scale) for li in labels_and_images]\n",
    "            images = np.stack(images)\n",
    "            labels = np.array(labels).astype(np.int32)\n",
    "            labels = np.reshape(\n",
    "            labels, (num_classes, num_samples_per_class))\n",
    "            labels = np.eye(num_classes, dtype=np.float32)[labels]\n",
    "            images = np.reshape(\n",
    "            images, (num_classes, num_samples_per_class, -1))\n",
    "\n",
    "            batch = np.concatenate([labels, images], 2)\n",
    "            if shuffle:\n",
    "                for p in range(num_samples_per_class):\n",
    "                    np.random.shuffle(batch[:, p])\n",
    "\n",
    "            labels = batch[:, :, :num_classes]\n",
    "            images = batch[:, :, num_classes:]\n",
    "\n",
    "            if swap:\n",
    "                labels = np.swapaxes(labels, 0, 1)\n",
    "                images = np.swapaxes(images, 0, 1)\n",
    "\n",
    "            all_image_batches.append(images)\n",
    "            all_label_batches.append(labels)\n",
    "        all_image_batches = np.stack(all_image_batches)\n",
    "        all_label_batches = np.stack(all_label_batches)\n",
    "        return all_image_batches, all_label_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RelationNet\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "class RelationNet(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, num_filters = 64, hidden_dim = 8):\n",
    "        super(RelationNet, self).__init__()\n",
    "#         self.num_filters = num_filters\n",
    "#         # self.latent_dim = latent_dim\n",
    "#         num_filter_list = [self.num_filters]*2\n",
    "#         self.convs = []\n",
    "#         for i, num_filter in enumerate(num_filter_list):\n",
    "#             block_parts = [\n",
    "#             layers.Conv2D(\n",
    "#               filters=num_filter,\n",
    "#               kernel_size=3,\n",
    "#               padding='SAME',\n",
    "#               activation='linear'),\n",
    "#             ]\n",
    "\n",
    "#             block_parts += [layers.BatchNormalization(momentum = 1)]\n",
    "#             block_parts += [layers.Activation('relu')]\n",
    "#             block_parts += [layers.MaxPool2D()]\n",
    "#             block = tf.keras.Sequential(block_parts, name='conv_block_%d' % i)\n",
    "#             self.__setattr__(\"conv%d\" % i, block)\n",
    "#             self.convs.append(block)\n",
    "#         self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = layers.Dense(hidden_dim,activation = 'relu')\n",
    "        self.fc2 = layers.Dense(1,activation = 'sigmoid')\n",
    "\n",
    "    def call(self, inp):\n",
    "        out = inp\n",
    "        # for conv in self.convs:\n",
    "          # out = conv(out)\n",
    "        # out = self.flatten(out)\n",
    "        out = self.fc2(self.fc1(out))\n",
    "        return out\n",
    "\n",
    "def RelationLoss(x_latent, q_latent, labels_onehot, num_classes, num_support, num_queries, relation_net):\n",
    "    \"\"\"\n",
    "    calculates the prototype network loss using the latent representation of x\n",
    "    and the latent representation of the query set\n",
    "    Args:\n",
    "      x_latent: latent representation of supports with shape [N*S, D], where D is the latent dimension\n",
    "      q_latent: latent representation of queries with shape [N*Q, D], where D is the latent dimension\n",
    "      labels_onehot: one-hot encodings of the labels of the queries with shape [N, Q, N]\n",
    "      num_classes: number of classes (N) for classification\n",
    "      num_support: number of examples (S) in the support set\n",
    "      num_queries: number of examples (Q) in the query set\n",
    "    Returns:\n",
    "      ce_loss: the cross entropy loss between the predicted labels and true labels\n",
    "      acc: the accuracy of classification on the queries\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x_latent, shape=[num_classes, num_support, -1])\n",
    "    # print(x.numpy().shape)\n",
    "    prototypes = tf.reduce_mean(x, axis = 1, keepdims=False) #(N, D)\n",
    "    prototypes_ext = tf.repeat(prototypes, repeats = [num_classes*num_queries]*num_classes, axis = 0) #(N*Q*N, D)\n",
    "    q_ext = tf.tile(q_latent, multiples = [num_classes,1]) # (N*N*Q, D)\n",
    "    labels_ = tf.reshape(labels_onehot, [-1, num_classes]) #(N*Q, N)\n",
    "    scores_ = relation_net(tf.concat([q_ext, prototypes_ext], axis = -1)) #(N*NQ, 1)\n",
    "    scores_ = tf.split(scores_,num_classes,0)\n",
    "    scores = tf.concat(scores_, axis = -1) #(NQ,N)\n",
    "\n",
    "    loss = losses.mean_squared_error(labels_, scores) #(NQ,)\n",
    "    loss = tf.reduce_mean(loss) #(1,)\n",
    "\n",
    "    # ce_loss = cross_entropy_loss(dist,tf.reshape(labels_onehot, [-1, num_classes]), k_shot=1)\n",
    "    acc = accuracy(tf.argmax(input=labels_, axis=1), tf.argmax(input=scores, axis=1))\n",
    "    # print(ce_loss.numpy())\n",
    "    # print(acc.numpy())\n",
    "\n",
    "    # print(error)\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "#Shape checking\n",
    "\n",
    "# q = tf.random.uniform(shape = [10,5])\n",
    "# print(q.shape)\n",
    "# q_ext = tf.tile(q, multiples = [2,1])\n",
    "# q_rep = tf.repeat(q, repeats = [2], axis = 0)\n",
    "# print(q_rep.shape)\n",
    "# print(q)\n",
    "# print(q_rep)\n",
    "# print(tf.concat([q,q], axis = -1))\n",
    "\n",
    "\n",
    "# t = tf.random.uniform(shape = [12,1])\n",
    "# t_ = tf.split(t,3,0)\n",
    "# t__ = tf.concat(t_, axis = -1)\n",
    "\n",
    "# t1 = tf.random.uniform(shape = [12,1])\n",
    "# t1_ = tf.split(t1,3,0)\n",
    "# t1__ = tf.concat(t1_, axis = -1)\n",
    "\n",
    "# print(losses.mean_squared_error(t__,t1__,))\n",
    "\n",
    "# print(t)\n",
    "# print(t_)\n",
    "# print(t__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/ProtoNet\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class ProtoNet(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, num_filters, latent_dim):\n",
    "    super(ProtoNet, self).__init__()\n",
    "    self.num_filters = num_filters\n",
    "    self.latent_dim = latent_dim\n",
    "    num_filter_list = self.num_filters + [latent_dim]\n",
    "    self.convs = []\n",
    "    for i, num_filter in enumerate(num_filter_list):\n",
    "      block_parts = [\n",
    "        layers.Conv2D(\n",
    "          filters=num_filter,\n",
    "          kernel_size=3,\n",
    "          padding='SAME',\n",
    "          activation='linear'),\n",
    "      ]\n",
    "\n",
    "      block_parts += [layers.BatchNormalization()]\n",
    "      block_parts += [layers.Activation('relu')]\n",
    "      block_parts += [layers.MaxPool2D()]\n",
    "      block = tf.keras.Sequential(block_parts, name='conv_block_%d' % i)\n",
    "      self.__setattr__(\"conv%d\" % i, block)\n",
    "      self.convs.append(block)\n",
    "    self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "  def call(self, inp):\n",
    "    out = inp\n",
    "    for conv in self.convs:\n",
    "      out = conv(out)\n",
    "    out = self.flatten(out)\n",
    "    return out\n",
    "\n",
    "def ProtoLoss(x_latent, q_latent, labels_onehot, num_classes, num_support, num_queries):\n",
    "  \"\"\"\n",
    "    calculates the prototype network loss using the latent representation of x\n",
    "    and the latent representation of the query set\n",
    "    Args:\n",
    "      x_latent: latent representation of supports with shape [N*S, D], where D is the latent dimension\n",
    "      q_latent: latent representation of queries with shape [N*Q, D], where D is the latent dimension\n",
    "      labels_onehot: one-hot encodings of the labels of the queries with shape [N, Q, N]\n",
    "      num_classes: number of classes (N) for classification\n",
    "      num_support: number of examples (S) in the support set\n",
    "      num_queries: number of examples (Q) in the query set\n",
    "    Returns:\n",
    "      ce_loss: the cross entropy loss between the predicted labels and true labels\n",
    "      acc: the accuracy of classification on the queries\n",
    "  \"\"\"\n",
    "  x_latent = tf.reshape(x_latent,[num_classes,num_support,-1])\n",
    "  c = tf.reduce_mean(x_latent,axis=1)\n",
    "  def dist(q, c):\n",
    "    N_Q, D = q.shape\n",
    "    N = c.shape[0]\n",
    "    q = tf.tile(tf.expand_dims(q, axis=1), [1, N, 1])\n",
    "    c = tf.tile(tf.expand_dims(c, axis=0), [N_Q, 1, 1])\n",
    "    return tf.reduce_mean(tf.square(q-c), axis=2)\n",
    "  distances = tf.reshape(dist(q_latent, c), [num_classes,num_queries,num_classes])\n",
    "  ce_loss = cross_entropy_loss(-distances, labels_onehot, 1)\n",
    "  acc = accuracy(tf.argmax(labels_onehot, axis=-1),tf.argmax(tf.reshape(tf.nn.softmax(-distances), \n",
    "                                                                 [num_classes, num_queries, -1]), axis=-1))\n",
    "  #############################\n",
    "  return ce_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_ProtoNet\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def proto_net_train_step(model, optim, x, q, labels_ph, rel=None):\n",
    "    num_classes, num_support, im_height, im_width, channels = x.shape\n",
    "    num_queries = q.shape[1]\n",
    "    x = tf.reshape(x, [-1, im_height, im_width, channels])\n",
    "    q = tf.reshape(q, [-1, im_height, im_width, channels])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        x_latent = model(x)\n",
    "        q_latent = model(q)\n",
    "        if rel is None:\n",
    "            ce_loss, acc = ProtoLoss(x_latent, q_latent, labels_ph, num_classes, num_support, num_queries)\n",
    "        else:\n",
    "            ce_loss, acc = RelationLoss(x_latent, q_latent, labels_ph, num_classes, num_support, num_queries,rel)\n",
    "\n",
    "    if rel is None:\n",
    "        gradients = tape.gradient(ce_loss, model.trainable_variables)\n",
    "        optim.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    else:\n",
    "        gradients = tape.gradient(ce_loss, model.trainable_variables+rel.trainable_variables)\n",
    "        optim.apply_gradients(zip(gradients, model.trainable_variables+rel.trainable_variables))\n",
    "    \n",
    "    return ce_loss, acc\n",
    "\n",
    "def proto_net_eval(model, x, q, labels_ph,rel=None):\n",
    "  num_classes, num_support, im_height, im_width, channels = x.shape\n",
    "  num_queries = q.shape[1]\n",
    "  x = tf.reshape(x, [-1, im_height, im_width, channels])\n",
    "  q = tf.reshape(q, [-1, im_height, im_width, channels])\n",
    "\n",
    "  x_latent = model(x)\n",
    "  q_latent = model(q)\n",
    "  if rel is None:\n",
    "    ce_loss, acc = ProtoLoss(x_latent, q_latent, labels_ph, num_classes, num_support, num_queries)\n",
    "  else:\n",
    "    ce_loss, acc = RelationLoss(x_latent, q_latent, labels_ph, num_classes, num_support, num_queries,rel)\n",
    "\n",
    "  return ce_loss, acc \n",
    "\n",
    "def run_protonet(data_path='./omniglot_resized', n_way=20, k_shot=1, n_query=5, n_meta_test_way=20, \n",
    "                 k_meta_test_shot=5, n_meta_test_query=5,shear=None,scale=None, rel=False, n_epochs=20):\n",
    "  \n",
    "  n_episodes = 100\n",
    "\n",
    "  im_width, im_height, channels = 28, 28, 1\n",
    "  num_filters = 32\n",
    "  latent_dim = 16\n",
    "  num_conv_layers = 3\n",
    "  n_meta_test_episodes = 1000\n",
    "\n",
    "  model = ProtoNet([num_filters]*num_conv_layers, latent_dim)\n",
    "  if not rel:\n",
    "    rel_model=None\n",
    "  else:\n",
    "    rel_model = RelationNet()\n",
    "  optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    # call DataGenerator with k_shot+n_query samples per class\n",
    "  data_generator = DataGenerator(n_way, k_shot+n_query, n_meta_test_way, k_meta_test_shot+n_meta_test_query)\n",
    "  for ep in range(n_epochs):\n",
    "    for epi in range(n_episodes):\n",
    "      image_batch, label_batch = data_generator.sample_batch('meta_train',1,shuffle=False)\n",
    "      image, label = image_batch[0], label_batch[0]\n",
    "      support,query = image[:,:k_shot,:], image[:,k_shot:,:]\n",
    "      labels = label[:,k_shot:,:]\n",
    "      # Reshape\n",
    "      support = tf.reshape(support,[-1,k_shot,im_width, im_height, channels])\n",
    "      query = tf.reshape(query,[-1,n_query,im_width, im_height, channels])\n",
    "      #############################\n",
    "      ls, ac = proto_net_train_step(model, optimizer, x=support, q=query, labels_ph=labels, rel=rel_model)\n",
    "      if (epi+1) % 50 == 0:\n",
    "        image_batch, label_batch = data_generator.sample_batch('meta_val',1,shuffle=False)\n",
    "        image, label = image_batch[0], label_batch[0]\n",
    "        support,query = image[:,:k_shot,:], image[:,k_shot:,:]\n",
    "        labels = label[:,k_shot:,:]\n",
    "        # Reshape\n",
    "        support = tf.reshape(support,[-1,k_shot,im_width, im_height, channels])\n",
    "        query = tf.reshape(query,[-1,n_query,im_width, im_height, channels])\n",
    "        #############################\n",
    "        val_ls, val_ac = proto_net_eval(model, x=support, q=query, labels_ph=labels, rel=rel_model)\n",
    "        print('[epo {}/{}, epi {}/{}] => meta-training loss: {:.5f}, meta-training acc: {:.5f}, meta-val loss: {:.5f}, meta-val acc: {:.5f}'.format(ep+1,\n",
    "                                                                    n_epochs,\n",
    "                                                                    epi+1,\n",
    "                                                                    n_episodes,\n",
    "                                                                    ls,\n",
    "                                                                    ac,\n",
    "                                                                    val_ls,\n",
    "                                                                    val_ac))\n",
    "\n",
    "  print('Testing...')\n",
    "  meta_test_accuracies = []\n",
    "  for epi in range(n_meta_test_episodes):\n",
    "    # sample a batch of test data and partition into\n",
    "    # support and query sets\n",
    "    image_batch, label_batch = data_generator.sample_batch('meta_test',1,shuffle=False,shear=shear,scale=scale)\n",
    "    image, label = image_batch[0], label_batch[0]\n",
    "    support,query = image[:,:k_meta_test_shot,:], image[:,k_meta_test_shot:,:]\n",
    "    labels = label[:,k_meta_test_shot:,:]\n",
    "    # Reshape\n",
    "    support = tf.reshape(support,[-1,k_meta_test_shot,im_width, im_height, channels])\n",
    "    query = tf.reshape(query,[-1,n_meta_test_query,im_width, im_height, channels])\n",
    "    #############################\n",
    "    ls, ac = proto_net_eval(model, x=support, q=query, labels_ph=labels,rel=rel_model)\n",
    "    meta_test_accuracies.append(ac)\n",
    "    if (epi+1) % 50 == 0:\n",
    "      print('[meta-test episode {}/{}] => loss: {:.5f}, acc: {:.5f}'.format(epi+1, n_meta_test_episodes, ls, ac))\n",
    "  avg_acc = np.mean(meta_test_accuracies)\n",
    "  stds = np.std(meta_test_accuracies)\n",
    "  print('Average Meta-Test Accuracy: {:.5f}, Meta-Test Accuracy Std: {:.5f}'.format(avg_acc, stds))\n",
    "  # return meta_test_accuracies, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Performing shear=-0.8=========\n",
      "[epoch 1/20, episode 50/100] => meta-training loss: 1.30939, meta-training acc: 0.24000, meta-val loss: 1.04185, meta-val acc: 0.72000\n",
      "[epoch 1/20, episode 100/100] => meta-training loss: 0.68223, meta-training acc: 0.80000, meta-val loss: 0.94809, meta-val acc: 0.68000\n",
      "[epoch 2/20, episode 50/100] => meta-training loss: 0.50464, meta-training acc: 0.76000, meta-val loss: 0.54682, meta-val acc: 0.84000\n",
      "[epoch 2/20, episode 100/100] => meta-training loss: 0.92701, meta-training acc: 0.64000, meta-val loss: 0.23609, meta-val acc: 0.96000\n",
      "[epoch 3/20, episode 50/100] => meta-training loss: 0.34585, meta-training acc: 0.80000, meta-val loss: 0.59743, meta-val acc: 0.80000\n",
      "[epoch 3/20, episode 100/100] => meta-training loss: 1.03743, meta-training acc: 0.60000, meta-val loss: 1.04076, meta-val acc: 0.56000\n",
      "[epoch 4/20, episode 50/100] => meta-training loss: 0.50297, meta-training acc: 0.84000, meta-val loss: 1.12243, meta-val acc: 0.80000\n",
      "[epoch 4/20, episode 100/100] => meta-training loss: 0.44773, meta-training acc: 0.84000, meta-val loss: 0.80143, meta-val acc: 0.80000\n",
      "[epoch 5/20, episode 50/100] => meta-training loss: 0.59465, meta-training acc: 0.76000, meta-val loss: 0.86899, meta-val acc: 0.68000\n",
      "[epoch 5/20, episode 100/100] => meta-training loss: 0.24045, meta-training acc: 0.92000, meta-val loss: 0.81767, meta-val acc: 0.64000\n",
      "[epoch 6/20, episode 50/100] => meta-training loss: 0.39162, meta-training acc: 0.92000, meta-val loss: 0.29769, meta-val acc: 0.92000\n",
      "[epoch 6/20, episode 100/100] => meta-training loss: 0.45548, meta-training acc: 0.76000, meta-val loss: 0.51521, meta-val acc: 0.80000\n",
      "[epoch 7/20, episode 50/100] => meta-training loss: 0.31771, meta-training acc: 0.84000, meta-val loss: 1.02114, meta-val acc: 0.64000\n",
      "[epoch 7/20, episode 100/100] => meta-training loss: 0.39143, meta-training acc: 0.76000, meta-val loss: 0.16526, meta-val acc: 0.96000\n",
      "[epoch 8/20, episode 50/100] => meta-training loss: 0.30850, meta-training acc: 0.88000, meta-val loss: 0.20481, meta-val acc: 0.92000\n",
      "[epoch 8/20, episode 100/100] => meta-training loss: 0.84875, meta-training acc: 0.76000, meta-val loss: 0.76333, meta-val acc: 0.64000\n",
      "[epoch 9/20, episode 50/100] => meta-training loss: 0.32598, meta-training acc: 0.88000, meta-val loss: 0.56588, meta-val acc: 0.80000\n",
      "[epoch 9/20, episode 100/100] => meta-training loss: 0.23377, meta-training acc: 0.92000, meta-val loss: 0.27595, meta-val acc: 0.92000\n",
      "[epoch 10/20, episode 50/100] => meta-training loss: 0.49080, meta-training acc: 0.84000, meta-val loss: 0.92367, meta-val acc: 0.64000\n",
      "[epoch 10/20, episode 100/100] => meta-training loss: 1.06882, meta-training acc: 0.64000, meta-val loss: 0.62865, meta-val acc: 0.84000\n",
      "[epoch 11/20, episode 50/100] => meta-training loss: 0.36578, meta-training acc: 0.92000, meta-val loss: 0.20875, meta-val acc: 0.92000\n",
      "[epoch 11/20, episode 100/100] => meta-training loss: 0.06537, meta-training acc: 0.96000, meta-val loss: 0.23199, meta-val acc: 0.88000\n",
      "[epoch 12/20, episode 50/100] => meta-training loss: 0.31947, meta-training acc: 0.88000, meta-val loss: 0.29948, meta-val acc: 0.84000\n",
      "[epoch 12/20, episode 100/100] => meta-training loss: 0.74974, meta-training acc: 0.68000, meta-val loss: 0.14763, meta-val acc: 0.96000\n",
      "[epoch 13/20, episode 50/100] => meta-training loss: 0.51370, meta-training acc: 0.84000, meta-val loss: 0.19140, meta-val acc: 0.96000\n",
      "[epoch 13/20, episode 100/100] => meta-training loss: 0.42640, meta-training acc: 0.88000, meta-val loss: 0.35483, meta-val acc: 0.92000\n",
      "[epoch 14/20, episode 50/100] => meta-training loss: 1.13562, meta-training acc: 0.80000, meta-val loss: 0.61437, meta-val acc: 0.80000\n",
      "[epoch 14/20, episode 100/100] => meta-training loss: 0.66267, meta-training acc: 0.76000, meta-val loss: 0.12220, meta-val acc: 0.96000\n",
      "[epoch 15/20, episode 50/100] => meta-training loss: 0.22598, meta-training acc: 0.92000, meta-val loss: 1.38523, meta-val acc: 0.76000\n",
      "[epoch 15/20, episode 100/100] => meta-training loss: 0.63963, meta-training acc: 0.72000, meta-val loss: 0.41261, meta-val acc: 0.88000\n",
      "[epoch 16/20, episode 50/100] => meta-training loss: 0.44554, meta-training acc: 0.84000, meta-val loss: 0.35264, meta-val acc: 0.88000\n",
      "[epoch 16/20, episode 100/100] => meta-training loss: 0.04471, meta-training acc: 1.00000, meta-val loss: 0.21319, meta-val acc: 0.84000\n",
      "[epoch 17/20, episode 50/100] => meta-training loss: 0.12823, meta-training acc: 0.96000, meta-val loss: 0.13278, meta-val acc: 0.92000\n",
      "[epoch 17/20, episode 100/100] => meta-training loss: 0.13568, meta-training acc: 0.96000, meta-val loss: 0.23377, meta-val acc: 0.92000\n",
      "[epoch 18/20, episode 50/100] => meta-training loss: 0.04462, meta-training acc: 1.00000, meta-val loss: 0.21286, meta-val acc: 0.88000\n",
      "[epoch 18/20, episode 100/100] => meta-training loss: 0.22082, meta-training acc: 0.92000, meta-val loss: 0.27641, meta-val acc: 0.96000\n",
      "[epoch 19/20, episode 50/100] => meta-training loss: 0.68791, meta-training acc: 0.84000, meta-val loss: 0.55255, meta-val acc: 0.72000\n",
      "[epoch 19/20, episode 100/100] => meta-training loss: 0.38710, meta-training acc: 0.88000, meta-val loss: 0.24139, meta-val acc: 0.92000\n",
      "[epoch 20/20, episode 50/100] => meta-training loss: 0.11797, meta-training acc: 0.92000, meta-val loss: 0.14939, meta-val acc: 0.96000\n",
      "[epoch 20/20, episode 100/100] => meta-training loss: 0.00797, meta-training acc: 1.00000, meta-val loss: 0.20264, meta-val acc: 0.96000\n",
      "Testing...\n",
      "[meta-test episode 50/1000] => loss: 0.95967, acc: 0.52000\n",
      "[meta-test episode 100/1000] => loss: 1.63991, acc: 0.56000\n",
      "[meta-test episode 150/1000] => loss: 0.80606, acc: 0.80000\n",
      "[meta-test episode 200/1000] => loss: 1.28876, acc: 0.60000\n",
      "[meta-test episode 250/1000] => loss: 1.04516, acc: 0.68000\n",
      "[meta-test episode 300/1000] => loss: 1.41399, acc: 0.44000\n",
      "[meta-test episode 350/1000] => loss: 1.50514, acc: 0.52000\n",
      "[meta-test episode 400/1000] => loss: 1.34519, acc: 0.44000\n",
      "[meta-test episode 450/1000] => loss: 1.59836, acc: 0.48000\n",
      "[meta-test episode 500/1000] => loss: 0.91718, acc: 0.64000\n",
      "[meta-test episode 550/1000] => loss: 1.12721, acc: 0.68000\n",
      "[meta-test episode 600/1000] => loss: 0.73255, acc: 0.68000\n",
      "[meta-test episode 650/1000] => loss: 1.51313, acc: 0.68000\n",
      "[meta-test episode 700/1000] => loss: 1.36793, acc: 0.60000\n",
      "[meta-test episode 750/1000] => loss: 1.23371, acc: 0.60000\n",
      "[meta-test episode 800/1000] => loss: 1.68363, acc: 0.48000\n",
      "[meta-test episode 850/1000] => loss: 1.08845, acc: 0.60000\n",
      "[meta-test episode 900/1000] => loss: 1.34013, acc: 0.44000\n",
      "[meta-test episode 950/1000] => loss: 1.53983, acc: 0.48000\n",
      "[meta-test episode 1000/1000] => loss: 1.56301, acc: 0.28000\n",
      "Average Meta-Test Accuracy: 0.55932, Meta-Test Accuracy Std: 0.13949\n",
      "========Performing shear=-0.6=========\n",
      "[epoch 1/20, episode 50/100] => meta-training loss: 1.24931, meta-training acc: 0.40000, meta-val loss: 1.03077, meta-val acc: 0.72000\n",
      "[epoch 1/20, episode 100/100] => meta-training loss: 0.55278, meta-training acc: 0.80000, meta-val loss: 0.95776, meta-val acc: 0.72000\n",
      "[epoch 2/20, episode 50/100] => meta-training loss: 0.51400, meta-training acc: 0.72000, meta-val loss: 0.47425, meta-val acc: 0.88000\n",
      "[epoch 2/20, episode 100/100] => meta-training loss: 1.11385, meta-training acc: 0.48000, meta-val loss: 0.27256, meta-val acc: 0.96000\n",
      "[epoch 3/20, episode 50/100] => meta-training loss: 0.40473, meta-training acc: 0.84000, meta-val loss: 0.58376, meta-val acc: 0.76000\n",
      "[epoch 3/20, episode 100/100] => meta-training loss: 1.34605, meta-training acc: 0.44000, meta-val loss: 1.09453, meta-val acc: 0.60000\n",
      "[epoch 4/20, episode 50/100] => meta-training loss: 0.56429, meta-training acc: 0.84000, meta-val loss: 1.01833, meta-val acc: 0.64000\n",
      "[epoch 4/20, episode 100/100] => meta-training loss: 0.39861, meta-training acc: 0.84000, meta-val loss: 1.20437, meta-val acc: 0.68000\n",
      "[epoch 5/20, episode 50/100] => meta-training loss: 0.83478, meta-training acc: 0.64000, meta-val loss: 0.59263, meta-val acc: 0.80000\n",
      "[epoch 5/20, episode 100/100] => meta-training loss: 0.36628, meta-training acc: 0.84000, meta-val loss: 0.65188, meta-val acc: 0.72000\n",
      "[epoch 6/20, episode 50/100] => meta-training loss: 0.71536, meta-training acc: 0.80000, meta-val loss: 0.20716, meta-val acc: 0.92000\n",
      "[epoch 6/20, episode 100/100] => meta-training loss: 0.34140, meta-training acc: 0.88000, meta-val loss: 0.62909, meta-val acc: 0.80000\n",
      "[epoch 7/20, episode 50/100] => meta-training loss: 0.09130, meta-training acc: 1.00000, meta-val loss: 0.55908, meta-val acc: 0.72000\n",
      "[epoch 7/20, episode 100/100] => meta-training loss: 0.58251, meta-training acc: 0.92000, meta-val loss: 0.21068, meta-val acc: 1.00000\n",
      "[epoch 8/20, episode 50/100] => meta-training loss: 0.28506, meta-training acc: 0.92000, meta-val loss: 0.18914, meta-val acc: 0.96000\n",
      "[epoch 8/20, episode 100/100] => meta-training loss: 0.46785, meta-training acc: 0.92000, meta-val loss: 0.65491, meta-val acc: 0.72000\n",
      "[epoch 9/20, episode 50/100] => meta-training loss: 0.25443, meta-training acc: 0.84000, meta-val loss: 0.45400, meta-val acc: 0.92000\n",
      "[epoch 9/20, episode 100/100] => meta-training loss: 0.11183, meta-training acc: 0.96000, meta-val loss: 0.33733, meta-val acc: 0.92000\n",
      "[epoch 10/20, episode 50/100] => meta-training loss: 0.55895, meta-training acc: 0.88000, meta-val loss: 0.97751, meta-val acc: 0.68000\n",
      "[epoch 10/20, episode 100/100] => meta-training loss: 1.45488, meta-training acc: 0.68000, meta-val loss: 0.99426, meta-val acc: 0.60000\n",
      "[epoch 11/20, episode 50/100] => meta-training loss: 0.18667, meta-training acc: 0.96000, meta-val loss: 0.17729, meta-val acc: 0.96000\n",
      "[epoch 11/20, episode 100/100] => meta-training loss: 0.10674, meta-training acc: 0.96000, meta-val loss: 0.20004, meta-val acc: 0.96000\n",
      "[epoch 12/20, episode 50/100] => meta-training loss: 0.25879, meta-training acc: 0.84000, meta-val loss: 0.11312, meta-val acc: 0.96000\n",
      "[epoch 12/20, episode 100/100] => meta-training loss: 0.49689, meta-training acc: 0.76000, meta-val loss: 0.17070, meta-val acc: 0.96000\n",
      "[epoch 13/20, episode 50/100] => meta-training loss: 1.08897, meta-training acc: 0.72000, meta-val loss: 0.22200, meta-val acc: 0.88000\n",
      "[epoch 13/20, episode 100/100] => meta-training loss: 0.50388, meta-training acc: 0.88000, meta-val loss: 0.26284, meta-val acc: 0.92000\n",
      "[epoch 14/20, episode 50/100] => meta-training loss: 1.14430, meta-training acc: 0.80000, meta-val loss: 0.51449, meta-val acc: 0.80000\n",
      "[epoch 14/20, episode 100/100] => meta-training loss: 0.59939, meta-training acc: 0.76000, meta-val loss: 0.21789, meta-val acc: 0.96000\n",
      "[epoch 15/20, episode 50/100] => meta-training loss: 0.40336, meta-training acc: 0.88000, meta-val loss: 0.97649, meta-val acc: 0.80000\n",
      "[epoch 15/20, episode 100/100] => meta-training loss: 0.64339, meta-training acc: 0.80000, meta-val loss: 0.67884, meta-val acc: 0.76000\n",
      "[epoch 16/20, episode 50/100] => meta-training loss: 0.42319, meta-training acc: 0.88000, meta-val loss: 0.44632, meta-val acc: 0.92000\n",
      "[epoch 16/20, episode 100/100] => meta-training loss: 0.04340, meta-training acc: 1.00000, meta-val loss: 0.15537, meta-val acc: 0.88000\n",
      "[epoch 17/20, episode 50/100] => meta-training loss: 0.18933, meta-training acc: 0.96000, meta-val loss: 0.02984, meta-val acc: 1.00000\n",
      "[epoch 17/20, episode 100/100] => meta-training loss: 0.16769, meta-training acc: 0.92000, meta-val loss: 0.35840, meta-val acc: 0.84000\n",
      "[epoch 18/20, episode 50/100] => meta-training loss: 0.07677, meta-training acc: 1.00000, meta-val loss: 0.31713, meta-val acc: 0.88000\n",
      "[epoch 18/20, episode 100/100] => meta-training loss: 0.19386, meta-training acc: 0.92000, meta-val loss: 0.26360, meta-val acc: 0.88000\n",
      "[epoch 19/20, episode 50/100] => meta-training loss: 0.87348, meta-training acc: 0.72000, meta-val loss: 0.80330, meta-val acc: 0.64000\n",
      "[epoch 19/20, episode 100/100] => meta-training loss: 0.33512, meta-training acc: 0.96000, meta-val loss: 0.12537, meta-val acc: 0.92000\n",
      "[epoch 20/20, episode 50/100] => meta-training loss: 0.14303, meta-training acc: 0.96000, meta-val loss: 0.07000, meta-val acc: 1.00000\n",
      "[epoch 20/20, episode 100/100] => meta-training loss: 0.02072, meta-training acc: 1.00000, meta-val loss: 0.27265, meta-val acc: 0.92000\n",
      "Testing...\n",
      "[meta-test episode 50/1000] => loss: 0.99793, acc: 0.80000\n",
      "[meta-test episode 100/1000] => loss: 1.28608, acc: 0.60000\n",
      "[meta-test episode 150/1000] => loss: 0.50724, acc: 0.80000\n",
      "[meta-test episode 200/1000] => loss: 1.77430, acc: 0.64000\n",
      "[meta-test episode 250/1000] => loss: 0.94110, acc: 0.60000\n",
      "[meta-test episode 300/1000] => loss: 1.13557, acc: 0.68000\n",
      "[meta-test episode 350/1000] => loss: 1.02508, acc: 0.68000\n",
      "[meta-test episode 400/1000] => loss: 1.07185, acc: 0.56000\n",
      "[meta-test episode 450/1000] => loss: 0.93779, acc: 0.72000\n",
      "[meta-test episode 500/1000] => loss: 0.69314, acc: 0.72000\n",
      "[meta-test episode 550/1000] => loss: 0.75883, acc: 0.76000\n",
      "[meta-test episode 600/1000] => loss: 0.48956, acc: 0.84000\n",
      "[meta-test episode 650/1000] => loss: 0.71731, acc: 0.84000\n",
      "[meta-test episode 700/1000] => loss: 0.84451, acc: 0.68000\n",
      "[meta-test episode 750/1000] => loss: 0.91427, acc: 0.64000\n",
      "[meta-test episode 800/1000] => loss: 1.24309, acc: 0.56000\n",
      "[meta-test episode 850/1000] => loss: 0.87451, acc: 0.68000\n",
      "[meta-test episode 900/1000] => loss: 1.29792, acc: 0.36000\n",
      "[meta-test episode 950/1000] => loss: 1.26655, acc: 0.48000\n",
      "[meta-test episode 1000/1000] => loss: 1.29738, acc: 0.40000\n",
      "Average Meta-Test Accuracy: 0.64080, Meta-Test Accuracy Std: 0.13620\n",
      "========Performing shear=-0.4=========\n",
      "[epoch 1/20, episode 50/100] => meta-training loss: 1.21893, meta-training acc: 0.48000, meta-val loss: 1.21270, meta-val acc: 0.64000\n",
      "[epoch 1/20, episode 100/100] => meta-training loss: 0.49030, meta-training acc: 0.84000, meta-val loss: 1.10696, meta-val acc: 0.52000\n",
      "[epoch 2/20, episode 50/100] => meta-training loss: 0.56824, meta-training acc: 0.60000, meta-val loss: 0.53159, meta-val acc: 0.88000\n",
      "[epoch 2/20, episode 100/100] => meta-training loss: 1.30197, meta-training acc: 0.52000, meta-val loss: 0.24928, meta-val acc: 1.00000\n",
      "[epoch 3/20, episode 50/100] => meta-training loss: 0.53520, meta-training acc: 0.84000, meta-val loss: 0.63770, meta-val acc: 0.68000\n",
      "[epoch 3/20, episode 100/100] => meta-training loss: 1.55727, meta-training acc: 0.64000, meta-val loss: 1.15652, meta-val acc: 0.56000\n",
      "[epoch 4/20, episode 50/100] => meta-training loss: 0.49429, meta-training acc: 0.72000, meta-val loss: 1.18208, meta-val acc: 0.56000\n",
      "[epoch 4/20, episode 100/100] => meta-training loss: 0.44402, meta-training acc: 0.84000, meta-val loss: 1.11819, meta-val acc: 0.64000\n",
      "[epoch 5/20, episode 50/100] => meta-training loss: 0.69859, meta-training acc: 0.72000, meta-val loss: 0.51656, meta-val acc: 0.84000\n",
      "[epoch 5/20, episode 100/100] => meta-training loss: 0.34181, meta-training acc: 0.88000, meta-val loss: 0.68751, meta-val acc: 0.72000\n",
      "[epoch 6/20, episode 50/100] => meta-training loss: 0.43776, meta-training acc: 0.84000, meta-val loss: 0.53351, meta-val acc: 0.76000\n",
      "[epoch 6/20, episode 100/100] => meta-training loss: 0.24771, meta-training acc: 0.92000, meta-val loss: 0.32502, meta-val acc: 0.84000\n",
      "[epoch 7/20, episode 50/100] => meta-training loss: 0.12449, meta-training acc: 1.00000, meta-val loss: 0.56898, meta-val acc: 0.68000\n",
      "[epoch 7/20, episode 100/100] => meta-training loss: 0.40247, meta-training acc: 0.92000, meta-val loss: 0.20988, meta-val acc: 0.92000\n",
      "[epoch 8/20, episode 50/100] => meta-training loss: 0.56784, meta-training acc: 0.88000, meta-val loss: 0.33186, meta-val acc: 0.88000\n",
      "[epoch 8/20, episode 100/100] => meta-training loss: 0.65803, meta-training acc: 0.72000, meta-val loss: 0.70305, meta-val acc: 0.60000\n",
      "[epoch 9/20, episode 50/100] => meta-training loss: 0.62823, meta-training acc: 0.84000, meta-val loss: 0.49162, meta-val acc: 0.84000\n",
      "[epoch 9/20, episode 100/100] => meta-training loss: 0.16393, meta-training acc: 0.92000, meta-val loss: 0.26593, meta-val acc: 0.92000\n",
      "[epoch 10/20, episode 50/100] => meta-training loss: 0.34495, meta-training acc: 0.92000, meta-val loss: 0.69702, meta-val acc: 0.72000\n",
      "[epoch 10/20, episode 100/100] => meta-training loss: 1.14796, meta-training acc: 0.60000, meta-val loss: 0.85516, meta-val acc: 0.60000\n",
      "[epoch 11/20, episode 50/100] => meta-training loss: 0.27967, meta-training acc: 0.96000, meta-val loss: 0.09089, meta-val acc: 1.00000\n",
      "[epoch 11/20, episode 100/100] => meta-training loss: 0.07134, meta-training acc: 1.00000, meta-val loss: 0.27531, meta-val acc: 0.88000\n",
      "[epoch 12/20, episode 50/100] => meta-training loss: 0.08341, meta-training acc: 0.96000, meta-val loss: 0.12832, meta-val acc: 0.96000\n",
      "[epoch 12/20, episode 100/100] => meta-training loss: 0.51557, meta-training acc: 0.76000, meta-val loss: 0.11954, meta-val acc: 0.96000\n",
      "[epoch 13/20, episode 50/100] => meta-training loss: 0.70984, meta-training acc: 0.92000, meta-val loss: 0.15082, meta-val acc: 0.96000\n",
      "[epoch 13/20, episode 100/100] => meta-training loss: 0.32451, meta-training acc: 0.88000, meta-val loss: 0.26176, meta-val acc: 0.92000\n",
      "[epoch 14/20, episode 50/100] => meta-training loss: 1.20526, meta-training acc: 0.80000, meta-val loss: 0.61363, meta-val acc: 0.68000\n",
      "[epoch 14/20, episode 100/100] => meta-training loss: 0.37032, meta-training acc: 0.88000, meta-val loss: 0.24115, meta-val acc: 0.92000\n",
      "[epoch 15/20, episode 50/100] => meta-training loss: 0.20986, meta-training acc: 0.92000, meta-val loss: 1.28556, meta-val acc: 0.60000\n",
      "[epoch 15/20, episode 100/100] => meta-training loss: 0.58457, meta-training acc: 0.72000, meta-val loss: 0.72528, meta-val acc: 0.76000\n",
      "[epoch 16/20, episode 50/100] => meta-training loss: 0.48825, meta-training acc: 0.84000, meta-val loss: 0.28297, meta-val acc: 0.92000\n",
      "[epoch 16/20, episode 100/100] => meta-training loss: 0.04651, meta-training acc: 1.00000, meta-val loss: 0.42851, meta-val acc: 0.84000\n",
      "[epoch 17/20, episode 50/100] => meta-training loss: 0.17124, meta-training acc: 0.92000, meta-val loss: 0.08897, meta-val acc: 1.00000\n",
      "[epoch 17/20, episode 100/100] => meta-training loss: 0.23766, meta-training acc: 0.96000, meta-val loss: 0.29353, meta-val acc: 0.92000\n",
      "[epoch 18/20, episode 50/100] => meta-training loss: 0.04580, meta-training acc: 1.00000, meta-val loss: 0.10679, meta-val acc: 1.00000\n",
      "[epoch 18/20, episode 100/100] => meta-training loss: 0.17622, meta-training acc: 0.92000, meta-val loss: 0.23906, meta-val acc: 0.88000\n",
      "[epoch 19/20, episode 50/100] => meta-training loss: 0.45761, meta-training acc: 0.84000, meta-val loss: 0.72338, meta-val acc: 0.68000\n",
      "[epoch 19/20, episode 100/100] => meta-training loss: 0.40855, meta-training acc: 0.92000, meta-val loss: 0.24525, meta-val acc: 0.88000\n",
      "[epoch 20/20, episode 50/100] => meta-training loss: 0.26274, meta-training acc: 0.88000, meta-val loss: 0.12219, meta-val acc: 0.96000\n",
      "[epoch 20/20, episode 100/100] => meta-training loss: 0.13341, meta-training acc: 0.96000, meta-val loss: 0.24013, meta-val acc: 0.92000\n",
      "Testing...\n",
      "[meta-test episode 50/1000] => loss: 0.69104, acc: 0.76000\n",
      "[meta-test episode 100/1000] => loss: 0.66625, acc: 0.80000\n",
      "[meta-test episode 150/1000] => loss: 0.42920, acc: 0.88000\n",
      "[meta-test episode 200/1000] => loss: 1.10239, acc: 0.60000\n",
      "[meta-test episode 250/1000] => loss: 0.46168, acc: 0.88000\n",
      "[meta-test episode 300/1000] => loss: 1.21565, acc: 0.60000\n",
      "[meta-test episode 350/1000] => loss: 1.08363, acc: 0.88000\n",
      "[meta-test episode 400/1000] => loss: 1.23685, acc: 0.40000\n",
      "[meta-test episode 450/1000] => loss: 1.05854, acc: 0.60000\n",
      "[meta-test episode 500/1000] => loss: 0.82462, acc: 0.60000\n",
      "[meta-test episode 550/1000] => loss: 0.63231, acc: 0.88000\n",
      "[meta-test episode 600/1000] => loss: 0.35718, acc: 0.92000\n",
      "[meta-test episode 650/1000] => loss: 0.29077, acc: 0.96000\n",
      "[meta-test episode 700/1000] => loss: 0.43663, acc: 0.84000\n",
      "[meta-test episode 750/1000] => loss: 0.79270, acc: 0.72000\n",
      "[meta-test episode 800/1000] => loss: 1.05783, acc: 0.64000\n",
      "[meta-test episode 850/1000] => loss: 0.63344, acc: 0.72000\n",
      "[meta-test episode 900/1000] => loss: 1.04811, acc: 0.56000\n",
      "[meta-test episode 950/1000] => loss: 1.12102, acc: 0.64000\n",
      "[meta-test episode 1000/1000] => loss: 0.76419, acc: 0.72000\n",
      "Average Meta-Test Accuracy: 0.75200, Meta-Test Accuracy Std: 0.13044\n",
      "========Performing shear=-0.2=========\n",
      "[epoch 1/20, episode 50/100] => meta-training loss: 1.30663, meta-training acc: 0.48000, meta-val loss: 1.06866, meta-val acc: 0.60000\n",
      "[epoch 1/20, episode 100/100] => meta-training loss: 0.52892, meta-training acc: 0.80000, meta-val loss: 1.09390, meta-val acc: 0.56000\n",
      "[epoch 2/20, episode 50/100] => meta-training loss: 0.67607, meta-training acc: 0.68000, meta-val loss: 0.59094, meta-val acc: 0.68000\n",
      "[epoch 2/20, episode 100/100] => meta-training loss: 1.20429, meta-training acc: 0.44000, meta-val loss: 0.47629, meta-val acc: 0.88000\n",
      "[epoch 3/20, episode 50/100] => meta-training loss: 0.56551, meta-training acc: 0.84000, meta-val loss: 0.54864, meta-val acc: 0.80000\n",
      "[epoch 3/20, episode 100/100] => meta-training loss: 1.46103, meta-training acc: 0.60000, meta-val loss: 1.27546, meta-val acc: 0.60000\n",
      "[epoch 4/20, episode 50/100] => meta-training loss: 0.57584, meta-training acc: 0.76000, meta-val loss: 1.19442, meta-val acc: 0.56000\n",
      "[epoch 4/20, episode 100/100] => meta-training loss: 0.30998, meta-training acc: 0.92000, meta-val loss: 0.92425, meta-val acc: 0.76000\n",
      "[epoch 5/20, episode 50/100] => meta-training loss: 0.80913, meta-training acc: 0.68000, meta-val loss: 0.87429, meta-val acc: 0.76000\n",
      "[epoch 5/20, episode 100/100] => meta-training loss: 0.40932, meta-training acc: 0.88000, meta-val loss: 0.61102, meta-val acc: 0.80000\n",
      "[epoch 6/20, episode 50/100] => meta-training loss: 0.60879, meta-training acc: 0.84000, meta-val loss: 0.33955, meta-val acc: 0.84000\n",
      "[epoch 6/20, episode 100/100] => meta-training loss: 0.54252, meta-training acc: 0.80000, meta-val loss: 0.72008, meta-val acc: 0.68000\n",
      "[epoch 7/20, episode 50/100] => meta-training loss: 0.26188, meta-training acc: 0.96000, meta-val loss: 0.75874, meta-val acc: 0.68000\n",
      "[epoch 7/20, episode 100/100] => meta-training loss: 0.65303, meta-training acc: 0.84000, meta-val loss: 0.29992, meta-val acc: 0.84000\n",
      "[epoch 8/20, episode 50/100] => meta-training loss: 0.46250, meta-training acc: 0.88000, meta-val loss: 0.17232, meta-val acc: 1.00000\n",
      "[epoch 8/20, episode 100/100] => meta-training loss: 1.00174, meta-training acc: 0.80000, meta-val loss: 0.96065, meta-val acc: 0.60000\n",
      "[epoch 9/20, episode 50/100] => meta-training loss: 0.38456, meta-training acc: 0.84000, meta-val loss: 0.73260, meta-val acc: 0.72000\n",
      "[epoch 9/20, episode 100/100] => meta-training loss: 0.24438, meta-training acc: 0.92000, meta-val loss: 0.28000, meta-val acc: 0.88000\n",
      "[epoch 10/20, episode 50/100] => meta-training loss: 0.37607, meta-training acc: 0.88000, meta-val loss: 1.17928, meta-val acc: 0.72000\n",
      "[epoch 10/20, episode 100/100] => meta-training loss: 1.67293, meta-training acc: 0.60000, meta-val loss: 1.30377, meta-val acc: 0.56000\n",
      "[epoch 11/20, episode 50/100] => meta-training loss: 0.41993, meta-training acc: 0.92000, meta-val loss: 0.13999, meta-val acc: 1.00000\n",
      "[epoch 11/20, episode 100/100] => meta-training loss: 0.11781, meta-training acc: 1.00000, meta-val loss: 0.24555, meta-val acc: 0.92000\n",
      "[epoch 12/20, episode 50/100] => meta-training loss: 0.27631, meta-training acc: 0.92000, meta-val loss: 0.33402, meta-val acc: 0.88000\n",
      "[epoch 12/20, episode 100/100] => meta-training loss: 0.52758, meta-training acc: 0.76000, meta-val loss: 0.07279, meta-val acc: 1.00000\n",
      "[epoch 13/20, episode 50/100] => meta-training loss: 0.90149, meta-training acc: 0.72000, meta-val loss: 0.19937, meta-val acc: 1.00000\n",
      "[epoch 13/20, episode 100/100] => meta-training loss: 0.22213, meta-training acc: 0.96000, meta-val loss: 0.35404, meta-val acc: 0.88000\n",
      "[epoch 14/20, episode 50/100] => meta-training loss: 0.77992, meta-training acc: 0.80000, meta-val loss: 0.58303, meta-val acc: 0.72000\n",
      "[epoch 14/20, episode 100/100] => meta-training loss: 0.48142, meta-training acc: 0.80000, meta-val loss: 0.34773, meta-val acc: 0.80000\n",
      "[epoch 15/20, episode 50/100] => meta-training loss: 0.32090, meta-training acc: 0.88000, meta-val loss: 1.32051, meta-val acc: 0.76000\n",
      "[epoch 15/20, episode 100/100] => meta-training loss: 0.63092, meta-training acc: 0.80000, meta-val loss: 0.55787, meta-val acc: 0.76000\n",
      "[epoch 16/20, episode 50/100] => meta-training loss: 0.48818, meta-training acc: 0.84000, meta-val loss: 0.40161, meta-val acc: 0.92000\n",
      "[epoch 16/20, episode 100/100] => meta-training loss: 0.08226, meta-training acc: 1.00000, meta-val loss: 0.44320, meta-val acc: 0.92000\n",
      "[epoch 17/20, episode 50/100] => meta-training loss: 0.11837, meta-training acc: 1.00000, meta-val loss: 0.13057, meta-val acc: 0.96000\n",
      "[epoch 17/20, episode 100/100] => meta-training loss: 0.53796, meta-training acc: 0.76000, meta-val loss: 0.33409, meta-val acc: 0.88000\n",
      "[epoch 18/20, episode 50/100] => meta-training loss: 0.05646, meta-training acc: 1.00000, meta-val loss: 0.26653, meta-val acc: 0.84000\n",
      "[epoch 18/20, episode 100/100] => meta-training loss: 0.15346, meta-training acc: 0.92000, meta-val loss: 0.12330, meta-val acc: 1.00000\n",
      "[epoch 19/20, episode 50/100] => meta-training loss: 0.99261, meta-training acc: 0.52000, meta-val loss: 1.42442, meta-val acc: 0.56000\n",
      "[epoch 19/20, episode 100/100] => meta-training loss: 0.24048, meta-training acc: 0.96000, meta-val loss: 0.42974, meta-val acc: 0.88000\n",
      "[epoch 20/20, episode 50/100] => meta-training loss: 0.09949, meta-training acc: 1.00000, meta-val loss: 0.23822, meta-val acc: 0.92000\n",
      "[epoch 20/20, episode 100/100] => meta-training loss: 0.02694, meta-training acc: 1.00000, meta-val loss: 0.17769, meta-val acc: 0.96000\n",
      "Testing...\n",
      "[meta-test episode 50/1000] => loss: 0.99722, acc: 0.72000\n",
      "[meta-test episode 100/1000] => loss: 0.40074, acc: 0.84000\n",
      "[meta-test episode 150/1000] => loss: 0.41371, acc: 0.76000\n",
      "[meta-test episode 200/1000] => loss: 0.38240, acc: 0.88000\n",
      "[meta-test episode 250/1000] => loss: 0.49161, acc: 0.76000\n",
      "[meta-test episode 300/1000] => loss: 1.03468, acc: 0.72000\n",
      "[meta-test episode 350/1000] => loss: 0.24964, acc: 0.88000\n",
      "[meta-test episode 400/1000] => loss: 0.64869, acc: 0.72000\n",
      "[meta-test episode 450/1000] => loss: 0.66395, acc: 0.60000\n",
      "[meta-test episode 500/1000] => loss: 0.57089, acc: 0.76000\n",
      "[meta-test episode 550/1000] => loss: 0.31365, acc: 0.92000\n",
      "[meta-test episode 600/1000] => loss: 0.20338, acc: 0.96000\n",
      "[meta-test episode 650/1000] => loss: 0.27667, acc: 0.92000\n",
      "[meta-test episode 700/1000] => loss: 0.40998, acc: 0.80000\n",
      "[meta-test episode 750/1000] => loss: 0.48682, acc: 0.84000\n",
      "[meta-test episode 800/1000] => loss: 1.09341, acc: 0.52000\n",
      "[meta-test episode 850/1000] => loss: 0.23752, acc: 0.92000\n",
      "[meta-test episode 900/1000] => loss: 0.52796, acc: 0.88000\n",
      "[meta-test episode 950/1000] => loss: 0.41095, acc: 0.92000\n",
      "[meta-test episode 1000/1000] => loss: 0.83422, acc: 0.64000\n",
      "Average Meta-Test Accuracy: 0.81372, Meta-Test Accuracy Std: 0.11504\n",
      "========Performing shear=0.0=========\n",
      "[epoch 1/20, episode 50/100] => meta-training loss: 1.29895, meta-training acc: 0.40000, meta-val loss: 1.13623, meta-val acc: 0.64000\n",
      "[epoch 1/20, episode 100/100] => meta-training loss: 0.44434, meta-training acc: 0.84000, meta-val loss: 1.02566, meta-val acc: 0.60000\n",
      "[epoch 2/20, episode 50/100] => meta-training loss: 0.63138, meta-training acc: 0.60000, meta-val loss: 0.48766, meta-val acc: 0.84000\n",
      "[epoch 2/20, episode 100/100] => meta-training loss: 1.22054, meta-training acc: 0.44000, meta-val loss: 0.28848, meta-val acc: 0.92000\n",
      "[epoch 3/20, episode 50/100] => meta-training loss: 0.41527, meta-training acc: 0.84000, meta-val loss: 0.73144, meta-val acc: 0.72000\n",
      "[epoch 3/20, episode 100/100] => meta-training loss: 1.51115, meta-training acc: 0.60000, meta-val loss: 1.09100, meta-val acc: 0.60000\n",
      "[epoch 4/20, episode 50/100] => meta-training loss: 0.51968, meta-training acc: 0.92000, meta-val loss: 0.98950, meta-val acc: 0.60000\n",
      "[epoch 4/20, episode 100/100] => meta-training loss: 0.41500, meta-training acc: 0.88000, meta-val loss: 1.54708, meta-val acc: 0.68000\n",
      "[epoch 5/20, episode 50/100] => meta-training loss: 0.74029, meta-training acc: 0.68000, meta-val loss: 0.58354, meta-val acc: 0.72000\n",
      "[epoch 5/20, episode 100/100] => meta-training loss: 0.34533, meta-training acc: 0.88000, meta-val loss: 0.67945, meta-val acc: 0.72000\n",
      "[epoch 6/20, episode 50/100] => meta-training loss: 0.61018, meta-training acc: 0.88000, meta-val loss: 0.36443, meta-val acc: 0.84000\n",
      "[epoch 6/20, episode 100/100] => meta-training loss: 0.42928, meta-training acc: 0.96000, meta-val loss: 0.75737, meta-val acc: 0.64000\n",
      "[epoch 7/20, episode 50/100] => meta-training loss: 0.14170, meta-training acc: 0.96000, meta-val loss: 0.76311, meta-val acc: 0.64000\n",
      "[epoch 7/20, episode 100/100] => meta-training loss: 0.55244, meta-training acc: 0.76000, meta-val loss: 0.27905, meta-val acc: 0.84000\n",
      "[epoch 8/20, episode 50/100] => meta-training loss: 0.61900, meta-training acc: 0.88000, meta-val loss: 0.20580, meta-val acc: 0.88000\n",
      "[epoch 8/20, episode 100/100] => meta-training loss: 0.93033, meta-training acc: 0.64000, meta-val loss: 0.99157, meta-val acc: 0.60000\n",
      "[epoch 9/20, episode 50/100] => meta-training loss: 0.52811, meta-training acc: 0.84000, meta-val loss: 0.79878, meta-val acc: 0.72000\n",
      "[epoch 9/20, episode 100/100] => meta-training loss: 0.33959, meta-training acc: 0.92000, meta-val loss: 0.29884, meta-val acc: 0.88000\n",
      "[epoch 10/20, episode 50/100] => meta-training loss: 0.36315, meta-training acc: 0.84000, meta-val loss: 1.10621, meta-val acc: 0.56000\n",
      "[epoch 10/20, episode 100/100] => meta-training loss: 1.43756, meta-training acc: 0.56000, meta-val loss: 0.82099, meta-val acc: 0.64000\n",
      "[epoch 11/20, episode 50/100] => meta-training loss: 0.44113, meta-training acc: 0.92000, meta-val loss: 0.23147, meta-val acc: 0.96000\n",
      "[epoch 11/20, episode 100/100] => meta-training loss: 0.08160, meta-training acc: 1.00000, meta-val loss: 0.27374, meta-val acc: 0.84000\n",
      "[epoch 12/20, episode 50/100] => meta-training loss: 0.16235, meta-training acc: 0.96000, meta-val loss: 0.33663, meta-val acc: 0.84000\n",
      "[epoch 12/20, episode 100/100] => meta-training loss: 0.72198, meta-training acc: 0.72000, meta-val loss: 0.15437, meta-val acc: 0.96000\n",
      "[epoch 13/20, episode 50/100] => meta-training loss: 0.82333, meta-training acc: 0.80000, meta-val loss: 0.26575, meta-val acc: 0.88000\n",
      "[epoch 13/20, episode 100/100] => meta-training loss: 0.22181, meta-training acc: 0.88000, meta-val loss: 0.19206, meta-val acc: 0.92000\n",
      "[epoch 14/20, episode 50/100] => meta-training loss: 0.87320, meta-training acc: 0.80000, meta-val loss: 0.39351, meta-val acc: 0.80000\n",
      "[epoch 14/20, episode 100/100] => meta-training loss: 0.77694, meta-training acc: 0.76000, meta-val loss: 0.20718, meta-val acc: 0.92000\n",
      "[epoch 15/20, episode 50/100] => meta-training loss: 0.29822, meta-training acc: 0.92000, meta-val loss: 0.94253, meta-val acc: 0.80000\n",
      "[epoch 15/20, episode 100/100] => meta-training loss: 0.62702, meta-training acc: 0.76000, meta-val loss: 0.51256, meta-val acc: 0.80000\n",
      "[epoch 16/20, episode 50/100] => meta-training loss: 0.44896, meta-training acc: 0.88000, meta-val loss: 0.37543, meta-val acc: 0.92000\n",
      "[epoch 16/20, episode 100/100] => meta-training loss: 0.06540, meta-training acc: 1.00000, meta-val loss: 0.37726, meta-val acc: 0.92000\n",
      "[epoch 17/20, episode 50/100] => meta-training loss: 0.13410, meta-training acc: 0.92000, meta-val loss: 0.13177, meta-val acc: 1.00000\n",
      "[epoch 17/20, episode 100/100] => meta-training loss: 0.19208, meta-training acc: 0.96000, meta-val loss: 0.41357, meta-val acc: 0.84000\n",
      "[epoch 18/20, episode 50/100] => meta-training loss: 0.15930, meta-training acc: 0.88000, meta-val loss: 0.31991, meta-val acc: 0.80000\n",
      "[epoch 18/20, episode 100/100] => meta-training loss: 0.13278, meta-training acc: 0.96000, meta-val loss: 0.29230, meta-val acc: 0.92000\n",
      "[epoch 19/20, episode 50/100] => meta-training loss: 0.98142, meta-training acc: 0.52000, meta-val loss: 0.88980, meta-val acc: 0.60000\n",
      "[epoch 19/20, episode 100/100] => meta-training loss: 0.39662, meta-training acc: 0.88000, meta-val loss: 0.28846, meta-val acc: 0.92000\n",
      "[epoch 20/20, episode 50/100] => meta-training loss: 0.10923, meta-training acc: 1.00000, meta-val loss: 0.13300, meta-val acc: 1.00000\n",
      "[epoch 20/20, episode 100/100] => meta-training loss: 0.02678, meta-training acc: 1.00000, meta-val loss: 0.11397, meta-val acc: 1.00000\n",
      "Testing...\n",
      "[meta-test episode 50/1000] => loss: 0.37038, acc: 0.84000\n",
      "[meta-test episode 100/1000] => loss: 0.14694, acc: 0.96000\n",
      "[meta-test episode 150/1000] => loss: 0.08859, acc: 1.00000\n",
      "[meta-test episode 200/1000] => loss: 0.06154, acc: 1.00000\n",
      "[meta-test episode 250/1000] => loss: 0.11275, acc: 0.96000\n",
      "[meta-test episode 300/1000] => loss: 0.36592, acc: 0.84000\n",
      "[meta-test episode 350/1000] => loss: 0.29503, acc: 0.88000\n",
      "[meta-test episode 400/1000] => loss: 0.18657, acc: 0.92000\n",
      "[meta-test episode 450/1000] => loss: 0.17010, acc: 0.96000\n",
      "[meta-test episode 500/1000] => loss: 0.57171, acc: 0.72000\n",
      "[meta-test episode 550/1000] => loss: 0.20000, acc: 0.92000\n",
      "[meta-test episode 600/1000] => loss: 0.07924, acc: 0.92000\n",
      "[meta-test episode 650/1000] => loss: 0.00966, acc: 1.00000\n",
      "[meta-test episode 700/1000] => loss: 0.06434, acc: 1.00000\n",
      "[meta-test episode 750/1000] => loss: 0.25953, acc: 0.96000\n",
      "[meta-test episode 800/1000] => loss: 0.95104, acc: 0.80000\n",
      "[meta-test episode 850/1000] => loss: 0.12418, acc: 0.96000\n",
      "[meta-test episode 900/1000] => loss: 0.45224, acc: 0.92000\n",
      "[meta-test episode 950/1000] => loss: 0.18049, acc: 0.92000\n",
      "[meta-test episode 1000/1000] => loss: 0.82358, acc: 0.76000\n",
      "Average Meta-Test Accuracy: 0.89528, Meta-Test Accuracy Std: 0.09176\n",
      "========Performing shear=0.2=========\n",
      "[epoch 1/20, episode 50/100] => meta-training loss: 1.09226, meta-training acc: 0.52000, meta-val loss: 1.11468, meta-val acc: 0.68000\n",
      "[epoch 1/20, episode 100/100] => meta-training loss: 0.48318, meta-training acc: 0.84000, meta-val loss: 1.08870, meta-val acc: 0.52000\n",
      "[epoch 2/20, episode 50/100] => meta-training loss: 0.57956, meta-training acc: 0.60000, meta-val loss: 0.62745, meta-val acc: 0.72000\n",
      "[epoch 2/20, episode 100/100] => meta-training loss: 1.10273, meta-training acc: 0.52000, meta-val loss: 0.44869, meta-val acc: 0.84000\n",
      "[epoch 3/20, episode 50/100] => meta-training loss: 0.37740, meta-training acc: 0.84000, meta-val loss: 0.50653, meta-val acc: 0.72000\n",
      "[epoch 3/20, episode 100/100] => meta-training loss: 1.31628, meta-training acc: 0.64000, meta-val loss: 0.76923, meta-val acc: 0.68000\n",
      "[epoch 4/20, episode 50/100] => meta-training loss: 0.61351, meta-training acc: 0.80000, meta-val loss: 1.29725, meta-val acc: 0.52000\n",
      "[epoch 4/20, episode 100/100] => meta-training loss: 0.41161, meta-training acc: 0.92000, meta-val loss: 0.86304, meta-val acc: 0.84000\n",
      "[epoch 5/20, episode 50/100] => meta-training loss: 0.99318, meta-training acc: 0.64000, meta-val loss: 0.56298, meta-val acc: 0.80000\n",
      "[epoch 5/20, episode 100/100] => meta-training loss: 0.43791, meta-training acc: 0.84000, meta-val loss: 0.53914, meta-val acc: 0.68000\n",
      "[epoch 6/20, episode 50/100] => meta-training loss: 0.53927, meta-training acc: 0.84000, meta-val loss: 0.49668, meta-val acc: 0.80000\n",
      "[epoch 6/20, episode 100/100] => meta-training loss: 0.42116, meta-training acc: 0.88000, meta-val loss: 0.60608, meta-val acc: 0.72000\n",
      "[epoch 7/20, episode 50/100] => meta-training loss: 0.16222, meta-training acc: 0.96000, meta-val loss: 0.66897, meta-val acc: 0.76000\n",
      "[epoch 7/20, episode 100/100] => meta-training loss: 0.99276, meta-training acc: 0.68000, meta-val loss: 0.24235, meta-val acc: 0.84000\n",
      "[epoch 8/20, episode 50/100] => meta-training loss: 0.46481, meta-training acc: 0.88000, meta-val loss: 0.14820, meta-val acc: 0.96000\n",
      "[epoch 8/20, episode 100/100] => meta-training loss: 1.13101, meta-training acc: 0.60000, meta-val loss: 0.69220, meta-val acc: 0.76000\n",
      "[epoch 9/20, episode 50/100] => meta-training loss: 0.34522, meta-training acc: 0.92000, meta-val loss: 0.45877, meta-val acc: 0.80000\n",
      "[epoch 9/20, episode 100/100] => meta-training loss: 0.12757, meta-training acc: 0.96000, meta-val loss: 0.28085, meta-val acc: 0.92000\n",
      "[epoch 10/20, episode 50/100] => meta-training loss: 0.85089, meta-training acc: 0.84000, meta-val loss: 1.11316, meta-val acc: 0.68000\n",
      "[epoch 10/20, episode 100/100] => meta-training loss: 1.23290, meta-training acc: 0.64000, meta-val loss: 0.77901, meta-val acc: 0.64000\n",
      "[epoch 11/20, episode 50/100] => meta-training loss: 0.21701, meta-training acc: 0.96000, meta-val loss: 0.10053, meta-val acc: 1.00000\n",
      "[epoch 11/20, episode 100/100] => meta-training loss: 0.07136, meta-training acc: 1.00000, meta-val loss: 0.18955, meta-val acc: 0.96000\n",
      "[epoch 12/20, episode 50/100] => meta-training loss: 0.40737, meta-training acc: 0.84000, meta-val loss: 0.24805, meta-val acc: 0.92000\n",
      "[epoch 12/20, episode 100/100] => meta-training loss: 0.63110, meta-training acc: 0.68000, meta-val loss: 0.29002, meta-val acc: 0.96000\n",
      "[epoch 13/20, episode 50/100] => meta-training loss: 0.90109, meta-training acc: 0.80000, meta-val loss: 0.10795, meta-val acc: 1.00000\n",
      "[epoch 13/20, episode 100/100] => meta-training loss: 0.36900, meta-training acc: 0.88000, meta-val loss: 0.09615, meta-val acc: 0.96000\n",
      "[epoch 14/20, episode 50/100] => meta-training loss: 0.92190, meta-training acc: 0.80000, meta-val loss: 0.72952, meta-val acc: 0.72000\n",
      "[epoch 14/20, episode 100/100] => meta-training loss: 0.35837, meta-training acc: 0.88000, meta-val loss: 0.07085, meta-val acc: 0.96000\n",
      "[epoch 15/20, episode 50/100] => meta-training loss: 0.23814, meta-training acc: 0.88000, meta-val loss: 1.01705, meta-val acc: 0.80000\n",
      "[epoch 15/20, episode 100/100] => meta-training loss: 0.75227, meta-training acc: 0.76000, meta-val loss: 0.50589, meta-val acc: 0.76000\n",
      "[epoch 16/20, episode 50/100] => meta-training loss: 0.49916, meta-training acc: 0.80000, meta-val loss: 0.24998, meta-val acc: 0.92000\n",
      "[epoch 16/20, episode 100/100] => meta-training loss: 0.03584, meta-training acc: 1.00000, meta-val loss: 0.26213, meta-val acc: 0.88000\n",
      "[epoch 17/20, episode 50/100] => meta-training loss: 0.16509, meta-training acc: 0.92000, meta-val loss: 0.02584, meta-val acc: 1.00000\n",
      "[epoch 17/20, episode 100/100] => meta-training loss: 0.14369, meta-training acc: 0.96000, meta-val loss: 0.23480, meta-val acc: 0.84000\n",
      "[epoch 18/20, episode 50/100] => meta-training loss: 0.07785, meta-training acc: 0.96000, meta-val loss: 0.28621, meta-val acc: 0.84000\n",
      "[epoch 18/20, episode 100/100] => meta-training loss: 0.19595, meta-training acc: 0.96000, meta-val loss: 0.15036, meta-val acc: 0.92000\n",
      "[epoch 19/20, episode 50/100] => meta-training loss: 1.01331, meta-training acc: 0.60000, meta-val loss: 0.79300, meta-val acc: 0.68000\n",
      "[epoch 19/20, episode 100/100] => meta-training loss: 0.19104, meta-training acc: 0.96000, meta-val loss: 0.11486, meta-val acc: 1.00000\n",
      "[epoch 20/20, episode 50/100] => meta-training loss: 0.26843, meta-training acc: 0.84000, meta-val loss: 0.08570, meta-val acc: 0.96000\n",
      "[epoch 20/20, episode 100/100] => meta-training loss: 0.04857, meta-training acc: 1.00000, meta-val loss: 0.25268, meta-val acc: 0.88000\n",
      "Testing...\n",
      "[meta-test episode 50/1000] => loss: 0.78440, acc: 0.72000\n",
      "[meta-test episode 100/1000] => loss: 0.31571, acc: 0.80000\n",
      "[meta-test episode 150/1000] => loss: 0.45656, acc: 0.84000\n",
      "[meta-test episode 200/1000] => loss: 0.12924, acc: 1.00000\n",
      "[meta-test episode 250/1000] => loss: 0.56581, acc: 0.76000\n",
      "[meta-test episode 300/1000] => loss: 0.57807, acc: 0.84000\n",
      "[meta-test episode 350/1000] => loss: 0.71142, acc: 0.76000\n",
      "[meta-test episode 400/1000] => loss: 0.40776, acc: 0.76000\n",
      "[meta-test episode 450/1000] => loss: 0.48695, acc: 0.84000\n",
      "[meta-test episode 500/1000] => loss: 0.58927, acc: 0.72000\n",
      "[meta-test episode 550/1000] => loss: 0.13568, acc: 1.00000\n",
      "[meta-test episode 600/1000] => loss: 0.25381, acc: 0.88000\n",
      "[meta-test episode 650/1000] => loss: 0.12823, acc: 1.00000\n",
      "[meta-test episode 700/1000] => loss: 0.36899, acc: 0.88000\n",
      "[meta-test episode 750/1000] => loss: 0.50536, acc: 0.80000\n",
      "[meta-test episode 800/1000] => loss: 0.91430, acc: 0.64000\n",
      "[meta-test episode 850/1000] => loss: 0.13875, acc: 0.96000\n",
      "[meta-test episode 900/1000] => loss: 0.67002, acc: 0.80000\n",
      "[meta-test episode 950/1000] => loss: 0.63433, acc: 0.80000\n",
      "[meta-test episode 1000/1000] => loss: 0.77472, acc: 0.64000\n",
      "Average Meta-Test Accuracy: 0.83248, Meta-Test Accuracy Std: 0.11140\n",
      "========Performing shear=0.4=========\n",
      "[epoch 1/20, episode 50/100] => meta-training loss: 1.16528, meta-training acc: 0.36000, meta-val loss: 1.07711, meta-val acc: 0.64000\n",
      "[epoch 1/20, episode 100/100] => meta-training loss: 0.53056, meta-training acc: 0.80000, meta-val loss: 0.93399, meta-val acc: 0.72000\n",
      "[epoch 2/20, episode 50/100] => meta-training loss: 0.59091, meta-training acc: 0.60000, meta-val loss: 0.56425, meta-val acc: 0.80000\n",
      "[epoch 2/20, episode 100/100] => meta-training loss: 1.01876, meta-training acc: 0.56000, meta-val loss: 0.32321, meta-val acc: 0.96000\n",
      "[epoch 3/20, episode 50/100] => meta-training loss: 0.57187, meta-training acc: 0.84000, meta-val loss: 0.66084, meta-val acc: 0.76000\n",
      "[epoch 3/20, episode 100/100] => meta-training loss: 1.39333, meta-training acc: 0.40000, meta-val loss: 1.19657, meta-val acc: 0.56000\n",
      "[epoch 4/20, episode 50/100] => meta-training loss: 0.65002, meta-training acc: 0.76000, meta-val loss: 1.26867, meta-val acc: 0.64000\n",
      "[epoch 4/20, episode 100/100] => meta-training loss: 0.50646, meta-training acc: 0.76000, meta-val loss: 1.42552, meta-val acc: 0.76000\n",
      "[epoch 5/20, episode 50/100] => meta-training loss: 0.84354, meta-training acc: 0.64000, meta-val loss: 0.38550, meta-val acc: 0.84000\n",
      "[epoch 5/20, episode 100/100] => meta-training loss: 0.48275, meta-training acc: 0.84000, meta-val loss: 0.57705, meta-val acc: 0.80000\n",
      "[epoch 6/20, episode 50/100] => meta-training loss: 0.44558, meta-training acc: 0.88000, meta-val loss: 0.22953, meta-val acc: 0.88000\n",
      "[epoch 6/20, episode 100/100] => meta-training loss: 0.41366, meta-training acc: 0.88000, meta-val loss: 0.81581, meta-val acc: 0.72000\n",
      "[epoch 7/20, episode 50/100] => meta-training loss: 0.17878, meta-training acc: 0.96000, meta-val loss: 0.80966, meta-val acc: 0.60000\n",
      "[epoch 7/20, episode 100/100] => meta-training loss: 0.33679, meta-training acc: 0.92000, meta-val loss: 0.19122, meta-val acc: 0.96000\n",
      "[epoch 8/20, episode 50/100] => meta-training loss: 0.44738, meta-training acc: 0.84000, meta-val loss: 0.26848, meta-val acc: 0.92000\n",
      "[epoch 8/20, episode 100/100] => meta-training loss: 0.73519, meta-training acc: 0.84000, meta-val loss: 0.77756, meta-val acc: 0.60000\n",
      "[epoch 9/20, episode 50/100] => meta-training loss: 0.48500, meta-training acc: 0.88000, meta-val loss: 0.61546, meta-val acc: 0.80000\n",
      "[epoch 9/20, episode 100/100] => meta-training loss: 0.36549, meta-training acc: 0.88000, meta-val loss: 0.31048, meta-val acc: 0.80000\n",
      "[epoch 10/20, episode 50/100] => meta-training loss: 0.41353, meta-training acc: 0.88000, meta-val loss: 0.73568, meta-val acc: 0.60000\n",
      "[epoch 10/20, episode 100/100] => meta-training loss: 1.18198, meta-training acc: 0.72000, meta-val loss: 0.63420, meta-val acc: 0.76000\n",
      "[epoch 11/20, episode 50/100] => meta-training loss: 0.41735, meta-training acc: 0.96000, meta-val loss: 0.13151, meta-val acc: 0.96000\n",
      "[epoch 11/20, episode 100/100] => meta-training loss: 0.03095, meta-training acc: 1.00000, meta-val loss: 0.27068, meta-val acc: 0.84000\n",
      "[epoch 12/20, episode 50/100] => meta-training loss: 0.58944, meta-training acc: 0.80000, meta-val loss: 0.34934, meta-val acc: 0.84000\n",
      "[epoch 12/20, episode 100/100] => meta-training loss: 0.73349, meta-training acc: 0.76000, meta-val loss: 0.26590, meta-val acc: 0.96000\n",
      "[epoch 13/20, episode 50/100] => meta-training loss: 0.66110, meta-training acc: 0.88000, meta-val loss: 0.29291, meta-val acc: 0.88000\n",
      "[epoch 13/20, episode 100/100] => meta-training loss: 0.48330, meta-training acc: 0.88000, meta-val loss: 0.35910, meta-val acc: 0.88000\n",
      "[epoch 14/20, episode 50/100] => meta-training loss: 1.05025, meta-training acc: 0.80000, meta-val loss: 0.52849, meta-val acc: 0.76000\n",
      "[epoch 14/20, episode 100/100] => meta-training loss: 0.63224, meta-training acc: 0.84000, meta-val loss: 0.19042, meta-val acc: 0.92000\n",
      "[epoch 15/20, episode 50/100] => meta-training loss: 0.64251, meta-training acc: 0.76000, meta-val loss: 0.87312, meta-val acc: 0.80000\n",
      "[epoch 15/20, episode 100/100] => meta-training loss: 0.61003, meta-training acc: 0.84000, meta-val loss: 0.42375, meta-val acc: 0.88000\n",
      "[epoch 16/20, episode 50/100] => meta-training loss: 0.48649, meta-training acc: 0.88000, meta-val loss: 0.18764, meta-val acc: 1.00000\n",
      "[epoch 16/20, episode 100/100] => meta-training loss: 0.05420, meta-training acc: 1.00000, meta-val loss: 0.12754, meta-val acc: 0.92000\n",
      "[epoch 17/20, episode 50/100] => meta-training loss: 0.09749, meta-training acc: 0.92000, meta-val loss: 0.06515, meta-val acc: 0.96000\n",
      "[epoch 17/20, episode 100/100] => meta-training loss: 0.31163, meta-training acc: 0.80000, meta-val loss: 0.17816, meta-val acc: 0.96000\n",
      "[epoch 18/20, episode 50/100] => meta-training loss: 0.07625, meta-training acc: 0.96000, meta-val loss: 0.42381, meta-val acc: 0.80000\n",
      "[epoch 18/20, episode 100/100] => meta-training loss: 0.09859, meta-training acc: 1.00000, meta-val loss: 0.22482, meta-val acc: 0.96000\n",
      "[epoch 19/20, episode 50/100] => meta-training loss: 0.88759, meta-training acc: 0.64000, meta-val loss: 0.71909, meta-val acc: 0.68000\n",
      "[epoch 19/20, episode 100/100] => meta-training loss: 0.25423, meta-training acc: 0.92000, meta-val loss: 0.13708, meta-val acc: 0.92000\n",
      "[epoch 20/20, episode 50/100] => meta-training loss: 0.10696, meta-training acc: 1.00000, meta-val loss: 0.14391, meta-val acc: 0.96000\n",
      "[epoch 20/20, episode 100/100] => meta-training loss: 0.03481, meta-training acc: 1.00000, meta-val loss: 0.18918, meta-val acc: 0.96000\n",
      "Testing...\n",
      "[meta-test episode 50/1000] => loss: 0.96985, acc: 0.60000\n",
      "[meta-test episode 100/1000] => loss: 0.48588, acc: 0.96000\n",
      "[meta-test episode 150/1000] => loss: 1.05355, acc: 0.56000\n",
      "[meta-test episode 200/1000] => loss: 0.60784, acc: 0.88000\n",
      "[meta-test episode 250/1000] => loss: 0.55225, acc: 0.80000\n",
      "[meta-test episode 300/1000] => loss: 0.68413, acc: 0.68000\n",
      "[meta-test episode 350/1000] => loss: 1.31566, acc: 0.56000\n",
      "[meta-test episode 400/1000] => loss: 0.84514, acc: 0.68000\n",
      "[meta-test episode 450/1000] => loss: 0.86883, acc: 0.72000\n",
      "[meta-test episode 500/1000] => loss: 0.95972, acc: 0.60000\n",
      "[meta-test episode 550/1000] => loss: 0.43982, acc: 0.88000\n",
      "[meta-test episode 600/1000] => loss: 0.54341, acc: 0.88000\n",
      "[meta-test episode 650/1000] => loss: 0.66937, acc: 0.84000\n",
      "[meta-test episode 700/1000] => loss: 0.86388, acc: 0.48000\n",
      "[meta-test episode 750/1000] => loss: 0.84154, acc: 0.64000\n",
      "[meta-test episode 800/1000] => loss: 0.95083, acc: 0.68000\n",
      "[meta-test episode 850/1000] => loss: 0.42501, acc: 0.84000\n",
      "[meta-test episode 900/1000] => loss: 1.10435, acc: 0.60000\n",
      "[meta-test episode 950/1000] => loss: 1.06279, acc: 0.68000\n",
      "[meta-test episode 1000/1000] => loss: 1.11304, acc: 0.44000\n",
      "Average Meta-Test Accuracy: 0.72592, Meta-Test Accuracy Std: 0.12927\n",
      "========Performing shear=0.6=========\n",
      "[epoch 1/20, episode 50/100] => meta-training loss: 1.11508, meta-training acc: 0.40000, meta-val loss: 1.11786, meta-val acc: 0.72000\n",
      "[epoch 1/20, episode 100/100] => meta-training loss: 0.61461, meta-training acc: 0.80000, meta-val loss: 1.06369, meta-val acc: 0.48000\n",
      "[epoch 2/20, episode 50/100] => meta-training loss: 0.62793, meta-training acc: 0.68000, meta-val loss: 0.71801, meta-val acc: 0.68000\n",
      "[epoch 2/20, episode 100/100] => meta-training loss: 1.03715, meta-training acc: 0.56000, meta-val loss: 0.46713, meta-val acc: 0.96000\n",
      "[epoch 3/20, episode 50/100] => meta-training loss: 0.56357, meta-training acc: 0.76000, meta-val loss: 0.58944, meta-val acc: 0.68000\n",
      "[epoch 3/20, episode 100/100] => meta-training loss: 1.48480, meta-training acc: 0.52000, meta-val loss: 0.53265, meta-val acc: 0.80000\n",
      "[epoch 4/20, episode 50/100] => meta-training loss: 0.48679, meta-training acc: 0.76000, meta-val loss: 1.15258, meta-val acc: 0.56000\n",
      "[epoch 4/20, episode 100/100] => meta-training loss: 0.49640, meta-training acc: 0.76000, meta-val loss: 1.58093, meta-val acc: 0.76000\n",
      "[epoch 5/20, episode 50/100] => meta-training loss: 0.73166, meta-training acc: 0.60000, meta-val loss: 0.84520, meta-val acc: 0.68000\n",
      "[epoch 5/20, episode 100/100] => meta-training loss: 0.56208, meta-training acc: 0.84000, meta-val loss: 0.72196, meta-val acc: 0.68000\n",
      "[epoch 6/20, episode 50/100] => meta-training loss: 0.65431, meta-training acc: 0.80000, meta-val loss: 0.47980, meta-val acc: 0.84000\n",
      "[epoch 6/20, episode 100/100] => meta-training loss: 0.44520, meta-training acc: 0.88000, meta-val loss: 0.71539, meta-val acc: 0.72000\n",
      "[epoch 7/20, episode 50/100] => meta-training loss: 0.25382, meta-training acc: 0.96000, meta-val loss: 0.90218, meta-val acc: 0.64000\n",
      "[epoch 7/20, episode 100/100] => meta-training loss: 0.77466, meta-training acc: 0.80000, meta-val loss: 0.23248, meta-val acc: 0.96000\n",
      "[epoch 8/20, episode 50/100] => meta-training loss: 0.57520, meta-training acc: 0.88000, meta-val loss: 0.33882, meta-val acc: 0.80000\n",
      "[epoch 8/20, episode 100/100] => meta-training loss: 0.85131, meta-training acc: 0.72000, meta-val loss: 0.85290, meta-val acc: 0.68000\n",
      "[epoch 9/20, episode 50/100] => meta-training loss: 0.64204, meta-training acc: 0.84000, meta-val loss: 0.63826, meta-val acc: 0.76000\n",
      "[epoch 9/20, episode 100/100] => meta-training loss: 0.41716, meta-training acc: 0.88000, meta-val loss: 0.33351, meta-val acc: 0.92000\n",
      "[epoch 10/20, episode 50/100] => meta-training loss: 0.84365, meta-training acc: 0.64000, meta-val loss: 1.67312, meta-val acc: 0.60000\n",
      "[epoch 10/20, episode 100/100] => meta-training loss: 1.66530, meta-training acc: 0.60000, meta-val loss: 1.10858, meta-val acc: 0.52000\n",
      "[epoch 11/20, episode 50/100] => meta-training loss: 0.77785, meta-training acc: 0.84000, meta-val loss: 0.43569, meta-val acc: 0.84000\n",
      "[epoch 11/20, episode 100/100] => meta-training loss: 0.17475, meta-training acc: 1.00000, meta-val loss: 0.41911, meta-val acc: 0.84000\n",
      "[epoch 12/20, episode 50/100] => meta-training loss: 0.45425, meta-training acc: 0.80000, meta-val loss: 0.48923, meta-val acc: 0.80000\n",
      "[epoch 12/20, episode 100/100] => meta-training loss: 0.70412, meta-training acc: 0.76000, meta-val loss: 0.13016, meta-val acc: 1.00000\n",
      "[epoch 13/20, episode 50/100] => meta-training loss: 0.80200, meta-training acc: 0.80000, meta-val loss: 0.30683, meta-val acc: 0.96000\n",
      "[epoch 13/20, episode 100/100] => meta-training loss: 0.70046, meta-training acc: 0.72000, meta-val loss: 0.38627, meta-val acc: 0.88000\n",
      "[epoch 14/20, episode 50/100] => meta-training loss: 0.41458, meta-training acc: 0.80000, meta-val loss: 0.62059, meta-val acc: 0.76000\n",
      "[epoch 14/20, episode 100/100] => meta-training loss: 0.39815, meta-training acc: 0.80000, meta-val loss: 0.24424, meta-val acc: 0.84000\n",
      "[epoch 15/20, episode 50/100] => meta-training loss: 0.21023, meta-training acc: 0.88000, meta-val loss: 1.01010, meta-val acc: 0.68000\n",
      "[epoch 15/20, episode 100/100] => meta-training loss: 0.60603, meta-training acc: 0.68000, meta-val loss: 0.57328, meta-val acc: 0.80000\n",
      "[epoch 16/20, episode 50/100] => meta-training loss: 0.72343, meta-training acc: 0.68000, meta-val loss: 0.30221, meta-val acc: 0.92000\n",
      "[epoch 16/20, episode 100/100] => meta-training loss: 0.14656, meta-training acc: 0.96000, meta-val loss: 0.75175, meta-val acc: 0.80000\n",
      "[epoch 17/20, episode 50/100] => meta-training loss: 0.21327, meta-training acc: 0.96000, meta-val loss: 0.14637, meta-val acc: 0.96000\n",
      "[epoch 17/20, episode 100/100] => meta-training loss: 0.11127, meta-training acc: 0.96000, meta-val loss: 0.40461, meta-val acc: 0.80000\n",
      "[epoch 18/20, episode 50/100] => meta-training loss: 0.03519, meta-training acc: 1.00000, meta-val loss: 0.48266, meta-val acc: 0.84000\n",
      "[epoch 18/20, episode 100/100] => meta-training loss: 0.09403, meta-training acc: 1.00000, meta-val loss: 0.38152, meta-val acc: 0.84000\n",
      "[epoch 19/20, episode 50/100] => meta-training loss: 1.38649, meta-training acc: 0.36000, meta-val loss: 0.75846, meta-val acc: 0.68000\n",
      "[epoch 19/20, episode 100/100] => meta-training loss: 0.27210, meta-training acc: 0.88000, meta-val loss: 0.42356, meta-val acc: 0.80000\n",
      "[epoch 20/20, episode 50/100] => meta-training loss: 0.09891, meta-training acc: 1.00000, meta-val loss: 0.17150, meta-val acc: 0.88000\n",
      "[epoch 20/20, episode 100/100] => meta-training loss: 0.03147, meta-training acc: 1.00000, meta-val loss: 0.13720, meta-val acc: 0.92000\n",
      "Testing...\n",
      "[meta-test episode 50/1000] => loss: 0.79612, acc: 0.68000\n",
      "[meta-test episode 100/1000] => loss: 0.64854, acc: 0.76000\n",
      "[meta-test episode 150/1000] => loss: 1.42838, acc: 0.60000\n",
      "[meta-test episode 200/1000] => loss: 0.62351, acc: 0.88000\n",
      "[meta-test episode 250/1000] => loss: 0.82230, acc: 0.60000\n",
      "[meta-test episode 300/1000] => loss: 1.04742, acc: 0.64000\n",
      "[meta-test episode 350/1000] => loss: 1.81442, acc: 0.60000\n",
      "[meta-test episode 400/1000] => loss: 1.05918, acc: 0.72000\n",
      "[meta-test episode 450/1000] => loss: 1.32277, acc: 0.68000\n",
      "[meta-test episode 500/1000] => loss: 1.33195, acc: 0.60000\n",
      "[meta-test episode 550/1000] => loss: 0.64883, acc: 0.84000\n",
      "[meta-test episode 600/1000] => loss: 0.58223, acc: 0.80000\n",
      "[meta-test episode 650/1000] => loss: 0.61292, acc: 0.80000\n",
      "[meta-test episode 700/1000] => loss: 1.26146, acc: 0.56000\n",
      "[meta-test episode 750/1000] => loss: 1.13829, acc: 0.48000\n",
      "[meta-test episode 800/1000] => loss: 1.19477, acc: 0.56000\n",
      "[meta-test episode 850/1000] => loss: 0.62926, acc: 0.76000\n",
      "[meta-test episode 900/1000] => loss: 1.09329, acc: 0.60000\n",
      "[meta-test episode 950/1000] => loss: 1.39508, acc: 0.68000\n",
      "[meta-test episode 1000/1000] => loss: 1.22663, acc: 0.44000\n",
      "Average Meta-Test Accuracy: 0.65056, Meta-Test Accuracy Std: 0.14071\n",
      "========Performing shear=0.8=========\n",
      "[epoch 1/20, episode 50/100] => meta-training loss: 1.21000, meta-training acc: 0.56000, meta-val loss: 1.03724, meta-val acc: 0.68000\n",
      "[epoch 1/20, episode 100/100] => meta-training loss: 0.56121, meta-training acc: 0.84000, meta-val loss: 0.99957, meta-val acc: 0.60000\n",
      "[epoch 2/20, episode 50/100] => meta-training loss: 0.50697, meta-training acc: 0.68000, meta-val loss: 0.56721, meta-val acc: 0.76000\n",
      "[epoch 2/20, episode 100/100] => meta-training loss: 1.05499, meta-training acc: 0.40000, meta-val loss: 0.28846, meta-val acc: 1.00000\n",
      "[epoch 3/20, episode 50/100] => meta-training loss: 0.54803, meta-training acc: 0.80000, meta-val loss: 0.62510, meta-val acc: 0.68000\n",
      "[epoch 3/20, episode 100/100] => meta-training loss: 1.45370, meta-training acc: 0.52000, meta-val loss: 1.07707, meta-val acc: 0.56000\n",
      "[epoch 4/20, episode 50/100] => meta-training loss: 0.40643, meta-training acc: 0.92000, meta-val loss: 0.98047, meta-val acc: 0.64000\n",
      "[epoch 4/20, episode 100/100] => meta-training loss: 0.38780, meta-training acc: 0.88000, meta-val loss: 1.53580, meta-val acc: 0.68000\n",
      "[epoch 5/20, episode 50/100] => meta-training loss: 0.73194, meta-training acc: 0.72000, meta-val loss: 0.67716, meta-val acc: 0.80000\n",
      "[epoch 5/20, episode 100/100] => meta-training loss: 0.46078, meta-training acc: 0.92000, meta-val loss: 0.66749, meta-val acc: 0.64000\n",
      "[epoch 6/20, episode 50/100] => meta-training loss: 0.51934, meta-training acc: 0.88000, meta-val loss: 0.28485, meta-val acc: 0.92000\n",
      "[epoch 6/20, episode 100/100] => meta-training loss: 0.67981, meta-training acc: 0.72000, meta-val loss: 0.60094, meta-val acc: 0.84000\n",
      "[epoch 7/20, episode 50/100] => meta-training loss: 0.25572, meta-training acc: 0.88000, meta-val loss: 0.61262, meta-val acc: 0.88000\n",
      "[epoch 7/20, episode 100/100] => meta-training loss: 0.57838, meta-training acc: 0.80000, meta-val loss: 0.16684, meta-val acc: 0.96000\n",
      "[epoch 8/20, episode 50/100] => meta-training loss: 0.56231, meta-training acc: 0.84000, meta-val loss: 0.45481, meta-val acc: 0.80000\n",
      "[epoch 8/20, episode 100/100] => meta-training loss: 0.92215, meta-training acc: 0.72000, meta-val loss: 0.60599, meta-val acc: 0.80000\n",
      "[epoch 9/20, episode 50/100] => meta-training loss: 0.40255, meta-training acc: 0.92000, meta-val loss: 0.55192, meta-val acc: 0.76000\n",
      "[epoch 9/20, episode 100/100] => meta-training loss: 0.23253, meta-training acc: 0.92000, meta-val loss: 0.37857, meta-val acc: 0.88000\n",
      "[epoch 10/20, episode 50/100] => meta-training loss: 0.68613, meta-training acc: 0.64000, meta-val loss: 0.67407, meta-val acc: 0.68000\n",
      "[epoch 10/20, episode 100/100] => meta-training loss: 0.95064, meta-training acc: 0.72000, meta-val loss: 0.93068, meta-val acc: 0.64000\n",
      "[epoch 11/20, episode 50/100] => meta-training loss: 0.53129, meta-training acc: 0.92000, meta-val loss: 0.36507, meta-val acc: 0.88000\n",
      "[epoch 11/20, episode 100/100] => meta-training loss: 0.25198, meta-training acc: 0.92000, meta-val loss: 0.72301, meta-val acc: 0.68000\n",
      "[epoch 12/20, episode 50/100] => meta-training loss: 0.28781, meta-training acc: 0.88000, meta-val loss: 0.47037, meta-val acc: 0.76000\n",
      "[epoch 12/20, episode 100/100] => meta-training loss: 0.53563, meta-training acc: 0.80000, meta-val loss: 0.18504, meta-val acc: 0.96000\n",
      "[epoch 13/20, episode 50/100] => meta-training loss: 0.77735, meta-training acc: 0.84000, meta-val loss: 0.34768, meta-val acc: 0.96000\n",
      "[epoch 13/20, episode 100/100] => meta-training loss: 0.29768, meta-training acc: 0.92000, meta-val loss: 0.24394, meta-val acc: 0.92000\n",
      "[epoch 14/20, episode 50/100] => meta-training loss: 1.18717, meta-training acc: 0.80000, meta-val loss: 0.73327, meta-val acc: 0.76000\n",
      "[epoch 14/20, episode 100/100] => meta-training loss: 0.65741, meta-training acc: 0.80000, meta-val loss: 0.13752, meta-val acc: 0.96000\n",
      "[epoch 15/20, episode 50/100] => meta-training loss: 0.27379, meta-training acc: 0.92000, meta-val loss: 1.10991, meta-val acc: 0.80000\n",
      "[epoch 15/20, episode 100/100] => meta-training loss: 0.62504, meta-training acc: 0.72000, meta-val loss: 0.85284, meta-val acc: 0.64000\n",
      "[epoch 16/20, episode 50/100] => meta-training loss: 0.72167, meta-training acc: 0.64000, meta-val loss: 0.40687, meta-val acc: 0.92000\n",
      "[epoch 16/20, episode 100/100] => meta-training loss: 0.07043, meta-training acc: 1.00000, meta-val loss: 0.06602, meta-val acc: 1.00000\n",
      "[epoch 17/20, episode 50/100] => meta-training loss: 0.26458, meta-training acc: 0.84000, meta-val loss: 0.10082, meta-val acc: 1.00000\n",
      "[epoch 17/20, episode 100/100] => meta-training loss: 0.13800, meta-training acc: 0.96000, meta-val loss: 0.22025, meta-val acc: 0.96000\n",
      "[epoch 18/20, episode 50/100] => meta-training loss: 0.10041, meta-training acc: 0.96000, meta-val loss: 0.32389, meta-val acc: 0.88000\n",
      "[epoch 18/20, episode 100/100] => meta-training loss: 0.24879, meta-training acc: 0.88000, meta-val loss: 0.39284, meta-val acc: 0.84000\n",
      "[epoch 19/20, episode 50/100] => meta-training loss: 1.06693, meta-training acc: 0.64000, meta-val loss: 0.92654, meta-val acc: 0.68000\n",
      "[epoch 19/20, episode 100/100] => meta-training loss: 0.29198, meta-training acc: 0.92000, meta-val loss: 0.26505, meta-val acc: 0.88000\n",
      "[epoch 20/20, episode 50/100] => meta-training loss: 0.14545, meta-training acc: 0.96000, meta-val loss: 0.20295, meta-val acc: 0.92000\n",
      "[epoch 20/20, episode 100/100] => meta-training loss: 0.03785, meta-training acc: 1.00000, meta-val loss: 0.29111, meta-val acc: 0.84000\n",
      "Testing...\n",
      "[meta-test episode 50/1000] => loss: 1.04694, acc: 0.64000\n",
      "[meta-test episode 100/1000] => loss: 0.99346, acc: 0.68000\n",
      "[meta-test episode 150/1000] => loss: 1.48437, acc: 0.56000\n",
      "[meta-test episode 200/1000] => loss: 1.01202, acc: 0.68000\n",
      "[meta-test episode 250/1000] => loss: 1.19245, acc: 0.48000\n",
      "[meta-test episode 300/1000] => loss: 0.97417, acc: 0.52000\n",
      "[meta-test episode 350/1000] => loss: 1.36705, acc: 0.60000\n",
      "[meta-test episode 400/1000] => loss: 1.43819, acc: 0.52000\n",
      "[meta-test episode 450/1000] => loss: 1.45211, acc: 0.44000\n",
      "[meta-test episode 500/1000] => loss: 1.20257, acc: 0.60000\n",
      "[meta-test episode 550/1000] => loss: 0.96786, acc: 0.60000\n",
      "[meta-test episode 600/1000] => loss: 1.03294, acc: 0.64000\n",
      "[meta-test episode 650/1000] => loss: 1.07513, acc: 0.64000\n",
      "[meta-test episode 700/1000] => loss: 1.12672, acc: 0.60000\n",
      "[meta-test episode 750/1000] => loss: 1.49056, acc: 0.36000\n",
      "[meta-test episode 800/1000] => loss: 1.66558, acc: 0.48000\n",
      "[meta-test episode 850/1000] => loss: 0.97168, acc: 0.72000\n",
      "[meta-test episode 900/1000] => loss: 1.38193, acc: 0.36000\n",
      "[meta-test episode 950/1000] => loss: 1.50711, acc: 0.56000\n",
      "[meta-test episode 1000/1000] => loss: 1.39939, acc: 0.40000\n",
      "Average Meta-Test Accuracy: 0.55688, Meta-Test Accuracy Std: 0.13995\n"
     ]
    }
   ],
   "source": [
    "for p in range(-8,10,2):\n",
    "  p = p/10\n",
    "  print(f'\\n========================Performing shear={p}=========================\\n')\n",
    "  run_protonet(data_path='./omniglot', n_way=5, k_shot=1, n_query=5, n_meta_test_way=5,\n",
    "                 k_meta_test_shot=1, n_meta_test_query=5,shear=p,scale=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epo 1/50, epi 50/100] => meta-training loss: 0.16006, meta-training acc: 0.20000, meta-val loss: 0.16047, meta-val acc: 0.20000\n",
      "[epo 1/50, epi 100/100] => meta-training loss: 0.15937, meta-training acc: 0.20000, meta-val loss: 0.15974, meta-val acc: 0.20000\n",
      "[epo 2/50, epi 50/100] => meta-training loss: 0.15907, meta-training acc: 0.20000, meta-val loss: 0.15956, meta-val acc: 0.20000\n",
      "[epo 2/50, epi 100/100] => meta-training loss: 0.16001, meta-training acc: 0.20000, meta-val loss: 0.15918, meta-val acc: 0.20000\n",
      "[epo 3/50, epi 50/100] => meta-training loss: 0.15783, meta-training acc: 0.44000, meta-val loss: 0.15305, meta-val acc: 0.48000\n",
      "[epo 3/50, epi 100/100] => meta-training loss: 0.14588, meta-training acc: 0.60000, meta-val loss: 0.13734, meta-val acc: 0.52000\n",
      "[epo 4/50, epi 50/100] => meta-training loss: 0.13497, meta-training acc: 0.56000, meta-val loss: 0.14954, meta-val acc: 0.44000\n",
      "[epo 4/50, epi 100/100] => meta-training loss: 0.14249, meta-training acc: 0.56000, meta-val loss: 0.14319, meta-val acc: 0.48000\n",
      "[epo 5/50, epi 50/100] => meta-training loss: 0.12607, meta-training acc: 0.52000, meta-val loss: 0.12007, meta-val acc: 0.60000\n",
      "[epo 5/50, epi 100/100] => meta-training loss: 0.14976, meta-training acc: 0.32000, meta-val loss: 0.14892, meta-val acc: 0.28000\n",
      "[epo 6/50, epi 50/100] => meta-training loss: 0.15127, meta-training acc: 0.36000, meta-val loss: 0.11399, meta-val acc: 0.60000\n",
      "[epo 6/50, epi 100/100] => meta-training loss: 0.09687, meta-training acc: 0.84000, meta-val loss: 0.12538, meta-val acc: 0.56000\n",
      "[epo 7/50, epi 50/100] => meta-training loss: 0.11199, meta-training acc: 0.76000, meta-val loss: 0.15091, meta-val acc: 0.44000\n",
      "[epo 7/50, epi 100/100] => meta-training loss: 0.12622, meta-training acc: 0.64000, meta-val loss: 0.08449, meta-val acc: 0.84000\n",
      "[epo 8/50, epi 50/100] => meta-training loss: 0.10294, meta-training acc: 0.72000, meta-val loss: 0.10794, meta-val acc: 0.76000\n",
      "[epo 8/50, epi 100/100] => meta-training loss: 0.14579, meta-training acc: 0.52000, meta-val loss: 0.11022, meta-val acc: 0.64000\n",
      "[epo 9/50, epi 50/100] => meta-training loss: 0.11844, meta-training acc: 0.56000, meta-val loss: 0.11224, meta-val acc: 0.48000\n",
      "[epo 9/50, epi 100/100] => meta-training loss: 0.13056, meta-training acc: 0.44000, meta-val loss: 0.09975, meta-val acc: 0.88000\n",
      "[epo 10/50, epi 50/100] => meta-training loss: 0.10275, meta-training acc: 0.72000, meta-val loss: 0.12239, meta-val acc: 0.56000\n",
      "[epo 10/50, epi 100/100] => meta-training loss: 0.14648, meta-training acc: 0.52000, meta-val loss: 0.19010, meta-val acc: 0.24000\n",
      "[epo 11/50, epi 50/100] => meta-training loss: 0.09471, meta-training acc: 0.84000, meta-val loss: 0.10206, meta-val acc: 0.60000\n",
      "[epo 11/50, epi 100/100] => meta-training loss: 0.08105, meta-training acc: 0.92000, meta-val loss: 0.11074, meta-val acc: 0.52000\n",
      "[epo 12/50, epi 50/100] => meta-training loss: 0.09540, meta-training acc: 0.72000, meta-val loss: 0.08000, meta-val acc: 0.88000\n",
      "[epo 12/50, epi 100/100] => meta-training loss: 0.12099, meta-training acc: 0.72000, meta-val loss: 0.08322, meta-val acc: 0.80000\n",
      "[epo 13/50, epi 50/100] => meta-training loss: 0.13642, meta-training acc: 0.56000, meta-val loss: 0.13627, meta-val acc: 0.32000\n",
      "[epo 13/50, epi 100/100] => meta-training loss: 0.12503, meta-training acc: 0.52000, meta-val loss: 0.11021, meta-val acc: 0.68000\n",
      "[epo 14/50, epi 50/100] => meta-training loss: 0.11345, meta-training acc: 0.68000, meta-val loss: 0.13971, meta-val acc: 0.52000\n",
      "[epo 14/50, epi 100/100] => meta-training loss: 0.10695, meta-training acc: 0.72000, meta-val loss: 0.12697, meta-val acc: 0.76000\n",
      "[epo 15/50, epi 50/100] => meta-training loss: 0.12349, meta-training acc: 0.72000, meta-val loss: 0.13121, meta-val acc: 0.64000\n",
      "[epo 15/50, epi 100/100] => meta-training loss: 0.13115, meta-training acc: 0.72000, meta-val loss: 0.17847, meta-val acc: 0.52000\n",
      "[epo 16/50, epi 50/100] => meta-training loss: 0.10709, meta-training acc: 0.64000, meta-val loss: 0.08711, meta-val acc: 0.80000\n",
      "[epo 16/50, epi 100/100] => meta-training loss: 0.10649, meta-training acc: 0.56000, meta-val loss: 0.07025, meta-val acc: 0.96000\n",
      "[epo 17/50, epi 50/100] => meta-training loss: 0.10567, meta-training acc: 0.60000, meta-val loss: 0.10655, meta-val acc: 0.64000\n",
      "[epo 17/50, epi 100/100] => meta-training loss: 0.09213, meta-training acc: 0.84000, meta-val loss: 0.10549, meta-val acc: 0.68000\n",
      "[epo 18/50, epi 50/100] => meta-training loss: 0.10011, meta-training acc: 0.68000, meta-val loss: 0.09592, meta-val acc: 0.88000\n",
      "[epo 18/50, epi 100/100] => meta-training loss: 0.08653, meta-training acc: 0.84000, meta-val loss: 0.07732, meta-val acc: 0.88000\n",
      "[epo 19/50, epi 50/100] => meta-training loss: 0.11621, meta-training acc: 0.52000, meta-val loss: 0.11150, meta-val acc: 0.60000\n",
      "[epo 19/50, epi 100/100] => meta-training loss: 0.12661, meta-training acc: 0.68000, meta-val loss: 0.10950, meta-val acc: 0.64000\n",
      "[epo 20/50, epi 50/100] => meta-training loss: 0.10310, meta-training acc: 0.60000, meta-val loss: 0.11884, meta-val acc: 0.64000\n",
      "[epo 20/50, epi 100/100] => meta-training loss: 0.15698, meta-training acc: 0.48000, meta-val loss: 0.09408, meta-val acc: 0.84000\n",
      "[epo 21/50, epi 50/100] => meta-training loss: 0.08165, meta-training acc: 0.84000, meta-val loss: 0.12158, meta-val acc: 0.72000\n",
      "[epo 21/50, epi 100/100] => meta-training loss: 0.06135, meta-training acc: 0.88000, meta-val loss: 0.06698, meta-val acc: 0.92000\n",
      "[epo 22/50, epi 50/100] => meta-training loss: 0.08463, meta-training acc: 0.84000, meta-val loss: 0.13610, meta-val acc: 0.52000\n",
      "[epo 22/50, epi 100/100] => meta-training loss: 0.07470, meta-training acc: 0.76000, meta-val loss: 0.08752, meta-val acc: 0.72000\n",
      "[epo 23/50, epi 50/100] => meta-training loss: 0.04898, meta-training acc: 1.00000, meta-val loss: 0.11206, meta-val acc: 0.64000\n",
      "[epo 23/50, epi 100/100] => meta-training loss: 0.07605, meta-training acc: 0.84000, meta-val loss: 0.16967, meta-val acc: 0.44000\n",
      "[epo 24/50, epi 50/100] => meta-training loss: 0.06673, meta-training acc: 0.88000, meta-val loss: 0.05586, meta-val acc: 0.92000\n",
      "[epo 24/50, epi 100/100] => meta-training loss: 0.13041, meta-training acc: 0.72000, meta-val loss: 0.12419, meta-val acc: 0.60000\n",
      "[epo 25/50, epi 50/100] => meta-training loss: 0.06903, meta-training acc: 0.88000, meta-val loss: 0.12677, meta-val acc: 0.52000\n",
      "[epo 25/50, epi 100/100] => meta-training loss: 0.11494, meta-training acc: 0.60000, meta-val loss: 0.16778, meta-val acc: 0.48000\n",
      "[epo 26/50, epi 50/100] => meta-training loss: 0.13888, meta-training acc: 0.72000, meta-val loss: 0.12344, meta-val acc: 0.52000\n",
      "[epo 26/50, epi 100/100] => meta-training loss: 0.11036, meta-training acc: 0.64000, meta-val loss: 0.08106, meta-val acc: 0.76000\n",
      "[epo 27/50, epi 50/100] => meta-training loss: 0.07308, meta-training acc: 0.72000, meta-val loss: 0.08982, meta-val acc: 0.88000\n",
      "[epo 27/50, epi 100/100] => meta-training loss: 0.11280, meta-training acc: 0.76000, meta-val loss: 0.09648, meta-val acc: 0.72000\n",
      "[epo 28/50, epi 50/100] => meta-training loss: 0.07424, meta-training acc: 0.88000, meta-val loss: 0.07471, meta-val acc: 0.88000\n",
      "[epo 28/50, epi 100/100] => meta-training loss: 0.05451, meta-training acc: 1.00000, meta-val loss: 0.11820, meta-val acc: 0.72000\n",
      "[epo 29/50, epi 50/100] => meta-training loss: 0.07278, meta-training acc: 0.88000, meta-val loss: 0.08344, meta-val acc: 0.76000\n",
      "[epo 29/50, epi 100/100] => meta-training loss: 0.08682, meta-training acc: 0.76000, meta-val loss: 0.12180, meta-val acc: 0.60000\n",
      "[epo 30/50, epi 50/100] => meta-training loss: 0.05532, meta-training acc: 0.92000, meta-val loss: 0.12253, meta-val acc: 0.60000\n",
      "[epo 30/50, epi 100/100] => meta-training loss: 0.05277, meta-training acc: 0.88000, meta-val loss: 0.05485, meta-val acc: 0.84000\n",
      "[epo 31/50, epi 50/100] => meta-training loss: 0.11795, meta-training acc: 0.76000, meta-val loss: 0.09902, meta-val acc: 0.68000\n",
      "[epo 31/50, epi 100/100] => meta-training loss: 0.10859, meta-training acc: 0.60000, meta-val loss: 0.07166, meta-val acc: 0.84000\n",
      "[epo 32/50, epi 50/100] => meta-training loss: 0.03718, meta-training acc: 1.00000, meta-val loss: 0.07809, meta-val acc: 0.88000\n",
      "[epo 32/50, epi 100/100] => meta-training loss: 0.14753, meta-training acc: 0.60000, meta-val loss: 0.05486, meta-val acc: 0.92000\n",
      "[epo 33/50, epi 50/100] => meta-training loss: 0.06945, meta-training acc: 0.76000, meta-val loss: 0.10686, meta-val acc: 0.60000\n",
      "[epo 33/50, epi 100/100] => meta-training loss: 0.08492, meta-training acc: 0.76000, meta-val loss: 0.09842, meta-val acc: 0.76000\n",
      "[epo 34/50, epi 50/100] => meta-training loss: 0.10130, meta-training acc: 0.60000, meta-val loss: 0.05745, meta-val acc: 0.96000\n",
      "[epo 34/50, epi 100/100] => meta-training loss: 0.08338, meta-training acc: 0.80000, meta-val loss: 0.11083, meta-val acc: 0.60000\n",
      "[epo 35/50, epi 50/100] => meta-training loss: 0.06789, meta-training acc: 0.88000, meta-val loss: 0.11179, meta-val acc: 0.60000\n",
      "[epo 35/50, epi 100/100] => meta-training loss: 0.13884, meta-training acc: 0.56000, meta-val loss: 0.04736, meta-val acc: 0.96000\n",
      "[epo 36/50, epi 50/100] => meta-training loss: 0.09326, meta-training acc: 0.72000, meta-val loss: 0.12302, meta-val acc: 0.80000\n",
      "[epo 36/50, epi 100/100] => meta-training loss: 0.08729, meta-training acc: 0.80000, meta-val loss: 0.08600, meta-val acc: 0.80000\n",
      "[epo 37/50, epi 50/100] => meta-training loss: 0.04159, meta-training acc: 1.00000, meta-val loss: 0.10282, meta-val acc: 0.68000\n",
      "[epo 37/50, epi 100/100] => meta-training loss: 0.09400, meta-training acc: 0.80000, meta-val loss: 0.09592, meta-val acc: 0.68000\n",
      "[epo 38/50, epi 50/100] => meta-training loss: 0.07645, meta-training acc: 0.80000, meta-val loss: 0.06610, meta-val acc: 0.88000\n",
      "[epo 38/50, epi 100/100] => meta-training loss: 0.08221, meta-training acc: 0.76000, meta-val loss: 0.11734, meta-val acc: 0.56000\n",
      "[epo 39/50, epi 50/100] => meta-training loss: 0.08969, meta-training acc: 0.72000, meta-val loss: 0.10425, meta-val acc: 0.60000\n",
      "[epo 39/50, epi 100/100] => meta-training loss: 0.12098, meta-training acc: 0.60000, meta-val loss: 0.05149, meta-val acc: 0.96000\n",
      "[epo 40/50, epi 50/100] => meta-training loss: 0.09657, meta-training acc: 0.68000, meta-val loss: 0.04801, meta-val acc: 0.92000\n",
      "[epo 40/50, epi 100/100] => meta-training loss: 0.06012, meta-training acc: 0.92000, meta-val loss: 0.06607, meta-val acc: 0.88000\n",
      "[epo 41/50, epi 50/100] => meta-training loss: 0.06140, meta-training acc: 0.76000, meta-val loss: 0.08036, meta-val acc: 0.80000\n",
      "[epo 41/50, epi 100/100] => meta-training loss: 0.07269, meta-training acc: 0.76000, meta-val loss: 0.10247, meta-val acc: 0.68000\n",
      "[epo 42/50, epi 50/100] => meta-training loss: 0.05315, meta-training acc: 0.92000, meta-val loss: 0.05928, meta-val acc: 0.92000\n",
      "[epo 42/50, epi 100/100] => meta-training loss: 0.06876, meta-training acc: 0.84000, meta-val loss: 0.12212, meta-val acc: 0.76000\n",
      "[epo 43/50, epi 50/100] => meta-training loss: 0.07412, meta-training acc: 0.84000, meta-val loss: 0.07550, meta-val acc: 0.80000\n",
      "[epo 43/50, epi 100/100] => meta-training loss: 0.07475, meta-training acc: 0.76000, meta-val loss: 0.03744, meta-val acc: 0.96000\n",
      "[epo 44/50, epi 50/100] => meta-training loss: 0.05212, meta-training acc: 0.96000, meta-val loss: 0.05476, meta-val acc: 0.92000\n",
      "[epo 44/50, epi 100/100] => meta-training loss: 0.03785, meta-training acc: 0.96000, meta-val loss: 0.13656, meta-val acc: 0.52000\n",
      "[epo 45/50, epi 50/100] => meta-training loss: 0.05269, meta-training acc: 0.92000, meta-val loss: 0.09549, meta-val acc: 0.72000\n",
      "[epo 45/50, epi 100/100] => meta-training loss: 0.04799, meta-training acc: 1.00000, meta-val loss: 0.19871, meta-val acc: 0.76000\n",
      "[epo 46/50, epi 50/100] => meta-training loss: 0.15305, meta-training acc: 0.60000, meta-val loss: 0.06869, meta-val acc: 0.84000\n",
      "[epo 46/50, epi 100/100] => meta-training loss: 0.07809, meta-training acc: 0.72000, meta-val loss: 0.07175, meta-val acc: 0.96000\n",
      "[epo 47/50, epi 50/100] => meta-training loss: 0.09312, meta-training acc: 0.80000, meta-val loss: 0.09403, meta-val acc: 0.80000\n",
      "[epo 47/50, epi 100/100] => meta-training loss: 0.09989, meta-training acc: 0.80000, meta-val loss: 0.09799, meta-val acc: 0.64000\n",
      "[epo 48/50, epi 50/100] => meta-training loss: 0.06361, meta-training acc: 0.76000, meta-val loss: 0.07575, meta-val acc: 0.80000\n",
      "[epo 48/50, epi 100/100] => meta-training loss: 0.07175, meta-training acc: 0.80000, meta-val loss: 0.14101, meta-val acc: 0.52000\n",
      "[epo 49/50, epi 50/100] => meta-training loss: 0.06741, meta-training acc: 0.88000, meta-val loss: 0.04020, meta-val acc: 0.96000\n",
      "[epo 49/50, epi 100/100] => meta-training loss: 0.08536, meta-training acc: 0.68000, meta-val loss: 0.11806, meta-val acc: 0.68000\n",
      "[epo 50/50, epi 50/100] => meta-training loss: 0.05815, meta-training acc: 0.92000, meta-val loss: 0.07034, meta-val acc: 0.80000\n",
      "[epo 50/50, epi 100/100] => meta-training loss: 0.06955, meta-training acc: 0.80000, meta-val loss: 0.06121, meta-val acc: 0.88000\n",
      "Testing...\n",
      "[meta-test episode 50/1000] => loss: 0.09731, acc: 0.80000\n",
      "[meta-test episode 100/1000] => loss: 0.06240, acc: 0.96000\n",
      "[meta-test episode 150/1000] => loss: 0.05439, acc: 0.88000\n",
      "[meta-test episode 200/1000] => loss: 0.03714, acc: 0.96000\n",
      "[meta-test episode 250/1000] => loss: 0.05757, acc: 0.96000\n",
      "[meta-test episode 300/1000] => loss: 0.05811, acc: 0.88000\n",
      "[meta-test episode 350/1000] => loss: 0.04568, acc: 0.92000\n",
      "[meta-test episode 400/1000] => loss: 0.04627, acc: 0.96000\n",
      "[meta-test episode 450/1000] => loss: 0.03526, acc: 0.96000\n",
      "[meta-test episode 500/1000] => loss: 0.05328, acc: 0.96000\n",
      "[meta-test episode 550/1000] => loss: 0.08371, acc: 0.68000\n",
      "[meta-test episode 600/1000] => loss: 0.11156, acc: 0.76000\n",
      "[meta-test episode 650/1000] => loss: 0.04418, acc: 0.92000\n",
      "[meta-test episode 700/1000] => loss: 0.16061, acc: 0.40000\n",
      "[meta-test episode 750/1000] => loss: 0.06304, acc: 1.00000\n",
      "[meta-test episode 800/1000] => loss: 0.06551, acc: 0.88000\n",
      "[meta-test episode 850/1000] => loss: 0.07227, acc: 0.80000\n",
      "[meta-test episode 900/1000] => loss: 0.06498, acc: 0.92000\n",
      "[meta-test episode 950/1000] => loss: 0.14762, acc: 0.76000\n",
      "[meta-test episode 1000/1000] => loss: 0.09008, acc: 0.76000\n",
      "Average Meta-Test Accuracy: 0.82136, Meta-Test Accuracy Std: 0.12905\n"
     ]
    }
   ],
   "source": [
    "run_protonet(data_path='./omniglot', n_way=5, k_shot=1, n_query=5, n_meta_test_way=5,\n",
    "                 k_meta_test_shot=1, n_meta_test_query=5,shear=0,scale=None,rel=True,n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
